<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Matthew Smith R Shenanigans</title>
    <link>/</link>
    <description>Recent content on Matthew Smith R Shenanigans</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Market Efficiency</title>
      <link>/courses/portfolio_theory/chap1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      
      <guid>/courses/portfolio_theory/chap1/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
true
&lt;/div&gt;

&lt;div id=&#34;introduction-to-efficient-markets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction to efficient markets&lt;/h2&gt;
&lt;p&gt;Each market participant participant has differing views on what data is telling them. The market is thus a weighted average of investor views. In &lt;em&gt;efficient markets&lt;/em&gt; all relevant information is reflected in the current share price of a stock.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Fama (&lt;a href=&#34;#ref-malkiel1970efficient&#34; role=&#34;doc-biblioref&#34;&gt;1970&lt;/a&gt;)&lt;/span&gt; suggested 3 types of market efficiency&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Weak form&lt;/em&gt;: In which the current market price reflects &lt;strong&gt;all information contained in past prices&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Semi-strong form&lt;/em&gt;: In which the current price reflects &lt;strong&gt;all publically avalable information&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Strong form&lt;/em&gt;: In which the current price relects &lt;strong&gt;all information, regardless of whether the information is public or not&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;random-walk&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Random Walk&lt;/h2&gt;
&lt;p&gt;A random walk in the context of finance suggests that changes in stock prices have the same distribution and are independent of each other and thus past stock prices cannot be used to predict the future price or movement. That is, stock prices take a random and unpredictable path.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{t+1}\)&lt;/span&gt; be a sequence of independently and identically distributed (i.i.d) random variables with an expected value of 0. Then, &lt;span class=&#34;math inline&#34;&gt;\(P_{t+1} = P_{t} + \epsilon_{t+1}\)&lt;/span&gt; is a random walk and &lt;span class=&#34;math inline&#34;&gt;\(P_{t+1} = P_{t} + \mu + \epsilon_{t+1}\)&lt;/span&gt; is a random walk with a drift component &lt;span class=&#34;math inline&#34;&gt;\(\mu &amp;gt; 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Market efficiency implies that prices reflect all current available information. As new information is made public then prices will adjust accordingly. We cannot predict this new information but we can take expectations such that, &lt;span class=&#34;math inline&#34;&gt;\(E(P_{t+1}) = P_{t} + E(\epsilon_{t+1})\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{t+1}\)&lt;/span&gt; is expected news about a given stock. The &lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon_{t+1}) = 0\)&lt;/span&gt; so &lt;span class=&#34;math inline&#34;&gt;\(E(P_{t+1}) = P_{t}\)&lt;/span&gt; but investors should obtain some compensation for bearing risk which is reflected in &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, therefore &lt;span class=&#34;math inline&#34;&gt;\(E(P_{t+1}) = P_{t} + \mu + E(\epsilon_{t+1})\)&lt;/span&gt; becomes &lt;span class=&#34;math inline&#34;&gt;\(E(P_{t+1}) = P_{t} + \mu\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon_{t+1})\)&lt;/span&gt; = 0.&lt;/p&gt;
&lt;p&gt;There are a few market phenomena that researchers and academics try to answer, the &lt;em&gt;value premium&lt;/em&gt; and &lt;em&gt;momentum premium&lt;/em&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;: &lt;span class=&#34;citation&#34;&gt;Fama and Blume (&lt;a href=&#34;#ref-fama1966filter&#34; role=&#34;doc-biblioref&#34;&gt;1966&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Alexander (&lt;a href=&#34;#ref-alexander1961price&#34; role=&#34;doc-biblioref&#34;&gt;1961&lt;/a&gt;)&lt;/span&gt; studied that some strategies can make money when transaction costs are not accounted for. Empirical findings have found that &lt;em&gt;value&lt;/em&gt; stocks (stocks with a high &lt;strong&gt;book-to-market&lt;/strong&gt; ratio) outperform &lt;em&gt;growth&lt;/em&gt; stocks (stocks with a low &lt;strong&gt;book-to-market&lt;/strong&gt; ratio) &lt;span class=&#34;citation&#34;&gt;Fama and French (&lt;a href=&#34;#ref-fama1992cross&#34; role=&#34;doc-biblioref&#34;&gt;1992&lt;/a&gt;)&lt;/span&gt;. Tech stocks are usually &lt;em&gt;growth&lt;/em&gt; stocks and have a low &lt;strong&gt;book value&lt;/strong&gt; since much of their value is in interlectual property and not in industrial/manufacturing plants, thus they have a lower relative &lt;strong&gt;book value&lt;/strong&gt; compared to their &lt;strong&gt;market value&lt;/strong&gt;. &lt;em&gt;Value&lt;/em&gt; stocks have a high book value relative to market value and would be manufacturing plants with large &lt;em&gt;fixed assets&lt;/em&gt; pushing the &lt;em&gt;book value&lt;/em&gt; up.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Momentum&lt;/strong&gt;: Past winners outperform past losers over a time period of 3 - 12 months &lt;span class=&#34;citation&#34;&gt;Wermers (&lt;a href=&#34;#ref-wermers1997momentum&#34; role=&#34;doc-biblioref&#34;&gt;1997&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both premiums imply that markets are inefficient. Not all stocks are correctly priced all the time. Some stocks are overpriced whilst other stocks are underpriced, however on average stocks are correctly priced.&lt;/p&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-alexander1961price&#34;&gt;
&lt;p&gt;Alexander, Sidney S. 1961. “Price Movements in Speculative Markets: Trends or Random Walks.” &lt;em&gt;Industrial Management Review (Pre-1986)&lt;/em&gt; 2 (2): 7.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-malkiel1970efficient&#34;&gt;
&lt;p&gt;Fama, Eugene F. 1970. “Efficient Capital Markets: A Review of Theory and Empirical Work.” &lt;em&gt;The Journal of Finance&lt;/em&gt; 25 (2): 383–417.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-fama1966filter&#34;&gt;
&lt;p&gt;Fama, Eugene F, and Marshall E Blume. 1966. “Filter Rules and Stock-Market Trading.” &lt;em&gt;The Journal of Business&lt;/em&gt; 39 (1): 226–41.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-fama1992cross&#34;&gt;
&lt;p&gt;Fama, Eugene F, and Kenneth R French. 1992. “The Cross-Section of Expected Stock Returns.” &lt;em&gt;The Journal of Finance&lt;/em&gt; 47 (2): 427–65.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wermers1997momentum&#34;&gt;
&lt;p&gt;Wermers, Russ. 1997. “Momentum Investment Strategies of Mutual Funds, Performance Persistence, and Survivorship Bias.” &lt;em&gt;Unpublished Working Paper, University of Colorado,[downloaded from Http://Bus. Colorado. Edu/Faculty/Wermers/.]&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s &lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Decision Boundary for a Series of Machine Learning Models</title>
      <link>/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;machine-learning-at-the-boundary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Machine Learning at the Boundary:&lt;/h1&gt;
&lt;p&gt;There is nothing new in the fact that machine learning models can outperform traditional econometric models but I want to show as part of my research why and how some models make given predictions or in this instance classifications.&lt;/p&gt;
&lt;p&gt;I wanted to show the decision boundary in which my binary classification model was making. That is, I wanted to show the partition space that splits my classification into each class. The problem and code can be split into a multi-classification problem with some tweeks.&lt;/p&gt;
&lt;div id=&#34;initialisation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Initialisation:&lt;/h2&gt;
&lt;p&gt;I first load in a series of packages and initialise a logistic function to convert log-odds to a logistic probability function later on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(patchwork)
library(ggplot2)
library(knitr)
library(kableExtra)
library(purrr)
library(stringr)
library(tidyr)
library(xgboost)
library(lightgbm)
library(keras)
library(tidyquant)
##################### Pre-define some functions ###################################
###################################################################################

logit2prob &amp;lt;- function(logit){
  odds &amp;lt;- exp(logit)
  prob &amp;lt;- odds / (1 + odds)
  return(prob)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The data:&lt;/h1&gt;
&lt;p&gt;I use the &lt;code&gt;iris&lt;/code&gt; dataset which contains information on 3 different plant variables collected by British statistican Ronald Fisher in 1936. The dataset consists of &lt;span class=&#34;math inline&#34;&gt;\(4\)&lt;/span&gt; different characteristics of plant species which should uniquely distinguish the &lt;span class=&#34;math inline&#34;&gt;\(3\)&lt;/span&gt; different species (&lt;em&gt;Setosa&lt;/em&gt;, &lt;em&gt;Virginica&lt;/em&gt; and &lt;em&gt;Versicolor&lt;/em&gt;). However, my problem required a binary classification problem and not a multi-classifciation problem. In the following code I import the &lt;code&gt;iris&lt;/code&gt; data and remove a type of plant Species &lt;code&gt;virginica&lt;/code&gt; to bring it from a multi-classification to a binary classification problem.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;###################################################################################
###################################################################################

data(iris)
df &amp;lt;- iris %&amp;gt;% 
  filter(Species != &amp;quot;virginica&amp;quot;) %&amp;gt;% 
  mutate(Species = +(Species == &amp;quot;versicolor&amp;quot;))
str(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    100 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : int  0 0 0 0 0 0 0 0 0 0 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;###################################################################################
###################################################################################&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I plot the data by first storing the &lt;code&gt;ggplot&lt;/code&gt; objects changing only the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; variables in each of the &lt;code&gt;plt&lt;/code&gt;’s.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plt1 &amp;lt;- df %&amp;gt;% 
  ggplot(aes(x = Sepal.Width, y = Sepal.Length, color = factor(Species))) +
  geom_point(size = 4) +
  theme_bw(base_size = 15) +
  theme(legend.position = &amp;quot;none&amp;quot;)

plt2 &amp;lt;- df %&amp;gt;% 
  ggplot(aes(x = Petal.Length, y = Sepal.Length, color = factor(Species))) +
  geom_point(size = 4) +
  theme_bw(base_size = 15) +
  theme(legend.position = &amp;quot;none&amp;quot;)

plt3 &amp;lt;- df %&amp;gt;% 
  ggplot(aes(x = Petal.Width, y = Sepal.Length, color = factor(Species))) +
  geom_point(size = 4) +
  theme_bw(base_size = 15) +
  theme(legend.position = &amp;quot;none&amp;quot;)

plt3 &amp;lt;- df %&amp;gt;% 
  ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = factor(Species))) +
  geom_point(size = 4) +
  theme_bw(base_size = 15) +
  theme(legend.position = &amp;quot;none&amp;quot;)

plt4 &amp;lt;- df %&amp;gt;% 
  ggplot(aes(x = Petal.Length, y = Sepal.Width, color = factor(Species))) +
  geom_point(size = 4) +
  theme_bw(base_size = 15) +
  theme(legend.position = &amp;quot;none&amp;quot;)

plt5 &amp;lt;- df %&amp;gt;% 
  ggplot(aes(x = Petal.Width, y = Sepal.Width, color = factor(Species))) +
  geom_point(size = 4) +
  theme_bw(base_size = 15) +
  theme(legend.position = &amp;quot;none&amp;quot;)

plt6 &amp;lt;- df %&amp;gt;% 
  ggplot(aes(x = Petal.Width, y = Sepal.Length, color = factor(Species))) +
  geom_point(size = 4) +
  theme_bw(base_size = 15) +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also wanted to use the new &lt;code&gt;patchwork&lt;/code&gt; package which makes displaying &lt;code&gt;ggplot&lt;/code&gt; plots very easy. i.e the below code plots our graphics as its written (1 top plot stretching the length of the grid space, 2 middle plots, another single plot and a further 2 more plots at the bottom.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;      (plt1)    /
  (plt2 + plt3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Alternatively, we can re-arrange the plots into any way we wish and plot them in the following way:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  (plt1 + plt2) / 
  (plt5 + plt6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Which I think looks awesome.&lt;/p&gt;
&lt;div id=&#34;objective&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Objective&lt;/h2&gt;
&lt;p&gt;The objective is to build a classification algorithm to distinguish between the two classes and then compute the decision boundaries in order to better see how the models made such predictions.&lt;/p&gt;
&lt;p&gt;In order to create the decision boundary plots for each variable combination we need the different combinatons of variables in the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;###################################################################################
###################################################################################

var_combos &amp;lt;- expand.grid(colnames(df[,1:4]), colnames(df[,1:4])) %&amp;gt;% 
  filter(!Var1 == Var2)

###################################################################################
###################################################################################&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var_combos %&amp;gt;% 
  head() %&amp;gt;% 
  kable(caption = &amp;quot;Variable Combinations&amp;quot;, escape = F, align = &amp;quot;c&amp;quot;, digits = 2) %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;), font_size = 9, fixed_thead = T, full_width = F) %&amp;gt;% 
  scroll_box(width = &amp;quot;100%&amp;quot;, height = &amp;quot;200px&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:200px; overflow-x: scroll; width:100%; &#34;&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;font-size: 9px; width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption style=&#34;font-size: initial !important;&#34;&gt;
&lt;span id=&#34;tab:unnamed-chunk-7&#34;&gt;Table 1: &lt;/span&gt;Variable Combinations
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
Var1
&lt;/th&gt;
&lt;th style=&#34;text-align:center;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;&#34;&gt;
Var2
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Width
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Length
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Petal.Length
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Length
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Petal.Width
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Length
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Length
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Width
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Petal.Length
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Width
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Petal.Width
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
Sepal.Width
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Next, I want to use the different variable combinations previously and create lists (one for each variable combination) and populate these lists with synthetic data - or data from the minimum to maximum value of each variable combination. This will act as our synthetically created test data in which we make predictions on and build the decision boundary.&lt;/p&gt;
&lt;p&gt;It’s important to note that the plots will eventually be 2 dimensional for illustrative purposes, therefore we only train the Machine Learning models on two variables, but for each combination of the two variables, these variables are the first two variables in the &lt;code&gt;boundary_lists&lt;/code&gt; data frames.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boundary_lists &amp;lt;- map2(
  .x = var_combos$Var1,
  .y = var_combos$Var2,
  ~select(df, .x, .y) %&amp;gt;% 
    summarise(
      minX = min(.[[1]], na.rm = TRUE),
      maxX = max(.[[1]], na.rm = TRUE),
      minY = min(.[[2]], na.rm = TRUE),
      maxY = max(.[[2]], na.rm = TRUE)
    )
) %&amp;gt;% 
  map(.,
      ~tibble(
        x = seq(.x$minX, .x$maxX, length.out = 200),
        y = seq(.x$minY, .x$maxY, length.out = 200),
      )
  ) %&amp;gt;% 
  map(.,
      ~tibble(
        xx = rep(.x$x, each = 200),
        yy = rep(.x$y, time = 200)
      )
  ) %&amp;gt;% 
  map2(.,
       asplit(var_combos, 1), ~ .x %&amp;gt;% 
         set_names(.y))

###################################################################################
###################################################################################&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see how the first 4 observations of the first and last two lists look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boundary_lists %&amp;gt;% 
  map(., ~head(., 4)) %&amp;gt;%  
  head(2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 4 x 2
##   Sepal.Width Sepal.Length
##         &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1           2         4.3 
## 2           2         4.31
## 3           2         4.33
## 4           2         4.34
## 
## [[2]]
## # A tibble: 4 x 2
##   Petal.Length Sepal.Length
##          &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1            1         4.3 
## 2            1         4.31
## 3            1         4.33
## 4            1         4.34&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boundary_lists %&amp;gt;% 
  map(., ~head(., 4)) %&amp;gt;%  
  tail(2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## # A tibble: 4 x 2
##   Sepal.Width Petal.Width
##         &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1           2       0.1  
## 2           2       0.109
## 3           2       0.117
## 4           2       0.126
## 
## [[2]]
## # A tibble: 4 x 2
##   Petal.Length Petal.Width
##          &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1            1       0.1  
## 2            1       0.109
## 3            1       0.117
## 4            1       0.126&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;training-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Training time:&lt;/h2&gt;
&lt;p&gt;Now that we have the synthetically created testing data set up, I want to train the models on the actual observed observations. I use each data point in the plots above as my training data. I apply the following models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logistic Model&lt;/li&gt;
&lt;li&gt;Support Vector Machine with a linear kernel&lt;/li&gt;
&lt;li&gt;Support Vector Machine with a polynomial kernel&lt;/li&gt;
&lt;li&gt;Support Vector Machine with a radial kernel&lt;/li&gt;
&lt;li&gt;Support Vector Machine with a sigmoid kernel&lt;/li&gt;
&lt;li&gt;Random Forest&lt;/li&gt;
&lt;li&gt;Extreme Gradiant Boosting (XGBoost) model with default parameters&lt;/li&gt;
&lt;li&gt;Single layer Keras Neural Network (with linear components)&lt;/li&gt;
&lt;li&gt;Deeper layer Keras Neural Network (with linear components)&lt;/li&gt;
&lt;li&gt;Deeper’er layer Keras Neural Network (with linear components)&lt;/li&gt;
&lt;li&gt;Light Gradient Boosting model (LightGBM) with default parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Side note: I am not an expert in Deep learning/Keras/Tensorflow, so I am sure better models will yield better decision boundaries but it was a fun task getting the different Machine Learning models to fit inside a &lt;code&gt;purrr&lt;/code&gt;, &lt;code&gt;map&lt;/code&gt; call.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;###################################################################################
###################################################################################
# params_lightGBM &amp;lt;- list(
#   objective = &amp;quot;binary&amp;quot;,
#   metric = &amp;quot;auc&amp;quot;,
#   min_data = 1
# )

# To install Light GBM try the following in your RStudio terinal

# git clone --recursive https://github.com/microsoft/LightGBM
# cd LightGBM
# Rscript build_r.R

models_list &amp;lt;- var_combos %&amp;gt;%
  mutate(modeln = str_c(&amp;#39;mod&amp;#39;, row_number()))  %&amp;gt;%
  pmap(~ 
         {
           
           xname = ..1
           yname = ..2
           modelname = ..3
           df %&amp;gt;%
             select(Species, xname, yname) %&amp;gt;%
             group_by(grp = &amp;#39;grp&amp;#39;) %&amp;gt;%
             nest() %&amp;gt;%
             mutate(models = map(data, ~{
               
               
               list(
                 # Logistic Model
                 Model_GLM = {
                   glm(Species ~ ., data = .x, family = binomial(link=&amp;#39;logit&amp;#39;))
                 },
                 # Support Vector Machine (linear)
                 Model_SVM_Linear = {
                   e1071::svm(Species ~ ., data = .x,  type = &amp;#39;C-classification&amp;#39;, kernel = &amp;#39;linear&amp;#39;)
                 },
                 # Support Vector Machine (polynomial)
                 Model_SVM_Polynomial = {
                   e1071::svm(Species ~ ., data = .x,  type = &amp;#39;C-classification&amp;#39;, kernel = &amp;#39;polynomial&amp;#39;)
                 },
                 # Support Vector Machine (sigmoid)
                 Model_SVM_radial = {
                   e1071::svm(Species ~ ., data = .x,  type = &amp;#39;C-classification&amp;#39;, kernel = &amp;#39;sigmoid&amp;#39;)
                 },
                 # Support Vector Machine (radial)
                 Model_SVM_radial_Sigmoid = {
                   e1071::svm(Species ~ ., data = .x,  type = &amp;#39;C-classification&amp;#39;, kernel = &amp;#39;radial&amp;#39;)
                 },
                 # Random Forest
                 Model_RF = {
                   randomForest::randomForest(formula = as.factor(Species) ~ ., data = .)
                 },
                 # Extreme Gradient Boosting
                 Model_XGB = {
                   xgboost(
                     objective = &amp;#39;binary:logistic&amp;#39;,
                     eval_metric = &amp;#39;auc&amp;#39;,
                     data = as.matrix(.x[, 2:3]),
                     label = as.matrix(.x$Species), # binary variable
                     nrounds = 10)
                 },
                 # Kera Neural Network
                 Model_Keras = {
                   mod &amp;lt;- keras_model_sequential() %&amp;gt;% 
                     layer_dense(units = 2, activation = &amp;#39;relu&amp;#39;, input_shape = 2) %&amp;gt;% 
                     layer_dense(units = 2, activation = &amp;#39;sigmoid&amp;#39;)
                   
                   mod %&amp;gt;% compile(
                     loss = &amp;#39;binary_crossentropy&amp;#39;,
                     optimizer_sgd(lr = 0.01, momentum = 0.9),
                     metrics = c(&amp;#39;accuracy&amp;#39;)
                   )
                   fit(mod, 
                       x = as.matrix(.x[, 2:3]),
                       y = to_categorical(.x$Species, 2),
                       epochs = 5,
                       batch_size = 5,
                       validation_split = 0
                   )
                   print(modelname)        
                   assign(modelname, mod)                      
                   
                 },
                 # Kera Neural Network
                 Model_Keras_2 = {
                   mod &amp;lt;- keras_model_sequential() %&amp;gt;% 
                     layer_dense(units = 2, activation = &amp;#39;relu&amp;#39;, input_shape = 2) %&amp;gt;%
                     layer_dense(units = 2, activation = &amp;#39;linear&amp;#39;, input_shape = 2) %&amp;gt;%
                     layer_dense(units = 2, activation = &amp;#39;sigmoid&amp;#39;)
                   
                   mod %&amp;gt;% compile(
                     loss = &amp;#39;binary_crossentropy&amp;#39;,
                     optimizer_sgd(lr = 0.01, momentum = 0.9),
                     metrics = c(&amp;#39;accuracy&amp;#39;)
                   )
                   fit(mod, 
                       x = as.matrix(.x[, 2:3]),
                       y = to_categorical(.x$Species, 2),
                       epochs = 5,
                       batch_size = 5,
                       validation_split = 0
                   )
                   print(modelname)        
                   assign(modelname, mod)                      
                   
                 },
                 # Kera Neural Network                 
                 Model_Keras_3 = {
                   mod &amp;lt;- keras_model_sequential() %&amp;gt;% 
                     layer_dense(units = 2, activation = &amp;#39;relu&amp;#39;, input_shape = 2) %&amp;gt;% 
                     layer_dense(units = 2, activation = &amp;#39;relu&amp;#39;, input_shape = 2) %&amp;gt;%
                     layer_dense(units = 2, activation = &amp;#39;linear&amp;#39;, input_shape = 2) %&amp;gt;%
                     layer_dense(units = 2, activation = &amp;#39;sigmoid&amp;#39;)
                   
                   mod %&amp;gt;% compile(
                     loss = &amp;#39;binary_crossentropy&amp;#39;,
                     optimizer_sgd(lr = 0.01, momentum = 0.9),
                     metrics = c(&amp;#39;accuracy&amp;#39;)
                   )
                   fit(mod, 
                       x = as.matrix(.x[, 2:3]),
                       y = to_categorical(.x$Species, 2),
                       epochs = 5,
                       batch_size = 5,
                       validation_split = 0
                   )
                   print(modelname)        
                   assign(modelname, mod)                      
                   
                 },
                 
                 # LightGBM model
                 Model_LightGBM = {
                   lgb.train(
                     data = lgb.Dataset(data = as.matrix(.x[, 2:3]), label = .x$Species),
                     objective = &amp;#39;binary&amp;#39;,
                     metric = &amp;#39;auc&amp;#39;,
                     min_data = 1
                     #params = params_lightGBM,
                     #learning_rate = 0.1
                   )
                 }
                 
                 
               )                      
               
             }                               
             ))                 
           
         }) %&amp;gt;% 
  map(
    ., ~unlist(., recursive = FALSE)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;testing-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Testing time:&lt;/h2&gt;
&lt;p&gt;Now that the models have been trained, we can begin makign the predictions on the synthetically created data we created in the &lt;code&gt;boundary_lists&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;models_predict &amp;lt;- map2(models_list, boundary_lists, ~{
  mods &amp;lt;- purrr::pluck(.x, &amp;quot;models&amp;quot;)
  dat &amp;lt;- .y
  map(mods, function(x)
    tryCatch({
      if(attr(x, &amp;quot;class&amp;quot;)[1] == &amp;quot;glm&amp;quot;){   
        # predict the logistic model
        tibble(
          modelname = attr(x, &amp;quot;class&amp;quot;)[1],
          prediction = predict(x, newdata = dat)
        ) %&amp;gt;% 
          mutate(
            prediction = logit2prob(prediction),
            prediction = case_when(
              prediction &amp;gt; 0.5 ~ 1,
              TRUE ~ 0
            )
          )
      }    
      else if(attr(x, &amp;quot;class&amp;quot;)[1] == &amp;quot;svm.formula&amp;quot;){ 
        # predict the SVM model
        tibble(
          modelname = attr(x, &amp;quot;class&amp;quot;)[1],
          prediction = as.numeric(as.character(predict(x, newdata = dat)))
        )
      }
      else if(attr(x, &amp;quot;class&amp;quot;)[1] == &amp;quot;randomForest.formula&amp;quot;){  
        # predict the RF model
        tibble(
          modelname = attr(x, &amp;quot;class&amp;quot;)[1],
          prediction = as.numeric(as.character(predict(x, newdata = dat)))
        )
      }    
      else if(attr(x, &amp;quot;class&amp;quot;)[1] == &amp;quot;xgb.Booster&amp;quot;){      
        # predict the XGBoost model
        tibble(
          modelname = attr(x, &amp;quot;class&amp;quot;)[1], 
          prediction = predict(x, newdata = as.matrix(dat), type = &amp;#39;prob&amp;#39;)
        ) %&amp;gt;% 
          mutate(
            prediction = case_when(
              prediction &amp;gt; 0.5 ~ 1,
              TRUE ~ 0
            )
          )
      }
      else if(attr(x, &amp;quot;class&amp;quot;)[1] == &amp;quot;keras.engine.sequential.Sequential&amp;quot;){
        # Keras Single Layer Neural Network
        tibble(
          modelname = attr(x, &amp;quot;class&amp;quot;)[1],
          prediction = predict_classes(object = x, x = as.matrix(dat))
        )
      }
      else if(attr(x, &amp;quot;class&amp;quot;)[2] == &amp;quot;keras.engine.training.Model&amp;quot;){
        # NOTE:::: This is a very crude hack to have multiple keras NN models
        # Needs fixing such that the models are named better - (not like) - (..., &amp;quot;class&amp;quot;)[2], ..., &amp;quot;class&amp;quot;)[3]... and so on.  
        # Keras Single Layer Neural Network
        tibble(
          modelname = attr(x, &amp;quot;class&amp;quot;)[2], # needs changing also.
          prediction = predict_classes(object = x, x = as.matrix(dat))
        )
      }
      else if(attr(x, &amp;quot;class&amp;quot;)[1] == &amp;quot;lgb.Booster&amp;quot;){
        # Light GBM model
        tibble(
          modelname = attr(x, &amp;quot;class&amp;quot;)[1],
          prediction = predict(object = x, data = as.matrix(dat), rawscore = FALSE)
        ) %&amp;gt;% 
          mutate(
            prediction = case_when(
              prediction &amp;gt; 0.5 ~ 1,
              TRUE ~ 0
            )
          )
      }
    }, error = function(e){
      print(&amp;#39;skipping\n&amp;#39;)
    }
    )
  )
}
) %&amp;gt;% 
  map(.,
      ~setNames(.,
                map(.,
                    ~c(.x$modelname[1]
                    )
                )
      )
  ) %&amp;gt;%
  map(.,
      ~map(.,
           ~setNames(.,
                     c(
                       paste0(.x$modelname[1], &amp;quot;_Model&amp;quot;),
                       paste0(.x$modelname[1], &amp;quot;_Prediction&amp;quot;)
                     )
           )
      )
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;calibrating-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calibrating the data&lt;/h2&gt;
&lt;p&gt;Now we have our trained models, along with predictions we can &lt;code&gt;map&lt;/code&gt; these predictions into data which we can plot using &lt;code&gt;ggplot&lt;/code&gt; and then arrange using &lt;code&gt;patchwork&lt;/code&gt;!.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_data &amp;lt;- map2(
  .x = boundary_lists,
  .y = map(
    models_predict,
    ~map(.,
         ~tibble(.)
    )
  ),
  ~bind_cols(.x, .y)
)

names(plot_data) &amp;lt;- map_chr(
  plot_data, ~c(
    paste(
      colnames(.)[1],
      &amp;quot;and&amp;quot;,
      colnames(.)[2],
      sep = &amp;quot;_&amp;quot;)
  )
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have our predictions we can create the &lt;code&gt;ggplots&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot_lists &amp;lt;- plot_data %&amp;gt;%
  map(
    .,
    ~select(
      .,
      -contains(&amp;quot;Model&amp;quot;)
    ) %&amp;gt;%
      pivot_longer(cols = contains(&amp;quot;Prediction&amp;quot;), names_to = &amp;quot;Model&amp;quot;, values_to = &amp;quot;Prediction&amp;quot;)
  ) %&amp;gt;%
  map(
    .x = .,
    ~ggplot() +
      geom_point(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2]),
        color = factor(!!rlang::sym(colnames(.x)[4]))
      ), data = .x) +
      geom_contour(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2]),
        z = !!rlang::sym(colnames(.x)[4])
      ), data = .x) +
      geom_point(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2]),
        color = factor(!!rlang::sym(colnames(df)[5]))  # this is the status variable
      ), size = 8, data = df) +
      geom_point(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2])
      ), size = 8, shape = 1, data = df) +
      facet_wrap(~Model) +
      theme_bw(base_size = 25) +
      theme(legend.position = &amp;quot;none&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plot all the different combinations of the decision boundaries. &lt;strong&gt;Note&lt;/strong&gt;: The above code will work better in your console, when I ran the code to compile the blog post the plots were too small. Therefore, I provide individual plots for a sample of the models &amp;amp; variable combinations.&lt;/p&gt;
&lt;p&gt;I first needed to select the first two columns which are the variables of interest (Petal.Width, Petal.Length, Sepal.Width and Sepal.Length). Then I wanted to take a random sample of the columns thereafter (which are the different Machine Learning Model predictions).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_data_sampled &amp;lt;- plot_data %&amp;gt;% 
  map(
    .,
    ~select(
      .,
      -contains(&amp;quot;Model&amp;quot;)
    ) %&amp;gt;% 
      select(.,
             c(1:2), sample(colnames(.), 2)
             ) %&amp;gt;% 
      pivot_longer(
        cols = contains(&amp;quot;Prediction&amp;quot;),
        names_to = &amp;quot;Model&amp;quot;,
        values_to = &amp;quot;Prediction&amp;quot;)
    ) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I can make the plots by taking a random sample of the lists.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_data_sampled %&amp;gt;% 
  rlist::list.sample(1) %&amp;gt;% 
  map(
    .x = .,
    ~ggplot() +
      geom_point(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2]),
        color = factor(!!rlang::sym(colnames(.x)[4]))
      ), data = .x) + 
      geom_contour(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2]),
        z = !!rlang::sym(colnames(.x)[4])
      ), data = .x) +
      geom_point(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2]),
        color = factor(!!rlang::sym(colnames(df)[5]))  # this is the status variable
      ), size = 3, data = df) +
      geom_point(aes(
        x = !!rlang::sym(colnames(.x)[1]),
        y = !!rlang::sym(colnames(.x)[2])
      ), size = 3, shape = 1, data = df) +
      facet_wrap(~Model) +
      #coord_flip() +
      theme_tq(base_family = &amp;quot;serif&amp;quot;) +
      theme(
        #aspect.ratio = 1,
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.position = &amp;quot;bottom&amp;quot;,
        #legend.title = element_text(size = 20),
        #legend.text = element_text(size = 10),
        axis.title = element_text(size = 20),
        axis.text = element_text(size = &amp;quot;15&amp;quot;),
        strip.text.x = element_text(size = 15),
        plot.title = element_text(size = 30, hjust = 0.5),
        strip.background = element_rect(fill = &amp;#39;darkred&amp;#39;),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        #axis.text.x = element_text(angle = 90),
        axis.text.y = element_text(angle = 90, hjust = 0.5),
        #axis.title.x = element_blank()
        legend.title = element_blank(),
        legend.text = element_text(size = 20)
      )
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Sepal.Width_and_Petal.Length&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Row indexes must be between 0 and the number of rows (0). Use `NA` as row index to obtain a row full of `NA` values.
## This warning is displayed once per session.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Some other random models:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## $Sepal.Width_and_Sepal.Length&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## $Sepal.Width_and_Sepal.Length&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## $Petal.Length_and_Sepal.Length&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## $Petal.Width_and_Petal.Length&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## $Petal.Length_and_Petal.Width&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in grDevices::contourLines(x = sort(unique(data$x)), y =
## sort(unique(data$y)), : todos los valores de z son iguales&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Not possible to generate contour data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Natually the linear models made a linear decision boundary. It looks like the random forest model overfit a little the data, where as the XGBoost and LightGBM models were able to make better, more generalisable decision boundaries. The Keras Neural Networks performed poorly because they should be trained better.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;glm&lt;/code&gt; = Logistic Model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keras.engine.sequential.Sequential Prediction...18&lt;/code&gt; = Single layer Neural Network&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keras.engine.sequential.Sequential Prediction...18&lt;/code&gt; = Deeper layer Neural Network&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keras.engine.sequential.Sequential Prediction...22&lt;/code&gt; = Deeper’er layer Neural Network&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lgb.Booster Prediction&lt;/code&gt; = Light Gradient Boosted Model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;randomForest.formula Prediction&lt;/code&gt; = Random Forest Model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;svm.formula Prediction...10&lt;/code&gt; = Support Vector Machine with a Sigmoid Kernel&lt;/li&gt;
&lt;li&gt;&lt;code&gt;svm.formula Prediction...12&lt;/code&gt; = Support Vector Machine with a Radial Kernel&lt;/li&gt;
&lt;li&gt;&lt;code&gt;svm.formula Prediction...6&lt;/code&gt; = Support Vector Machine with a Linear Kernel&lt;/li&gt;
&lt;li&gt;&lt;code&gt;svm.formula Prediction...8&lt;/code&gt; = Support Vector Machine with a Polynomial Kernel&lt;/li&gt;
&lt;li&gt;&lt;code&gt;xgb.Booster Prediction&lt;/code&gt; = Extreme Gradient Boosting Model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In many of the combinations the Keras Neural Network model just predicted all observations to be of a specific class (again by my poor tuning of the models and the fact that the Neural Networks only had 100 observations to learn from and 40,000 observation to predict on). That is, it coloured the whole background blue or red and made many mis-classifications. In some of the plots the Neural Networks managed to mae perfect classifications, in other it made strange decision boundaries. - Neural Networks are fun.&lt;/p&gt;
&lt;p&gt;As some brief analysis of the plots, it looks like the simple logistic model made near-perfect classifications. Which isn’t suprising given that each of the variable ralationships are linearly seperable. However, I have a preferece for XGBoost and LightGBM models since they can handle non-linear relationships through the incorporation of regularisation in its objective functions which allows them to make more robust decision boundaries. Random Forest models fail here which is why their decision boundary appears to do a good job but is also slightly erratic and sharpe in it’s decision boundaries.&lt;/p&gt;
&lt;p&gt;Of course it goes without saying that these decision boundaries can become significantly more complex and non-linear with the inclusion of more variables and higher dimensions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 1:length(plot_data)){
  print(ggplot_lists[[i]])
  }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;end-note&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;End note:&lt;/h2&gt;
&lt;p&gt;I wrote this model on an Amazon Ubuntu EC2 Instance however, when I went to compile the blog post in R on my Windows system I ran into some problems. These problems were mostly down to installing the &lt;code&gt;lightgbm&lt;/code&gt; package and package versions. The code was working without error using the following package versions (i.e. using the most up-to-date package versions)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.6.1 (2019-07-05)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17763)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252   
## [3] LC_MONETARY=Spanish_Spain.1252 LC_NUMERIC=C                  
## [5] LC_TIME=Spanish_Spain.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidyquant_0.5.7            quantmod_0.4-15           
##  [3] TTR_0.23-6                 PerformanceAnalytics_1.5.3
##  [5] xts_0.11-2                 zoo_1.8-6                 
##  [7] lubridate_1.7.4            keras_2.2.5.0             
##  [9] lightgbm_2.3.2             R6_2.4.1                  
## [11] xgboost_0.90.0.1           tidyr_1.0.0               
## [13] stringr_1.4.0              purrr_0.3.2               
## [15] kableExtra_1.1.0.9000      knitr_1.25.4              
## [17] ggplot2_3.2.1              patchwork_1.0.0           
## [19] dplyr_0.8.99.9000         
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.3           lattice_0.20-38      class_7.3-15        
##  [4] utf8_1.1.4           assertthat_0.2.1     zeallot_0.1.0       
##  [7] digest_0.6.24        e1071_1.7-2          evaluate_0.14       
## [10] httr_1.4.1           blogdown_0.15        pillar_1.4.3.9000   
## [13] tfruns_1.4           rlang_0.4.4          lazyeval_0.2.2      
## [16] curl_4.0             rstudioapi_0.10      data.table_1.12.8   
## [19] whisker_0.3-2        Matrix_1.2-17        reticulate_1.14-9001
## [22] rmarkdown_1.14       lobstr_1.1.1         labeling_0.3        
## [25] webshot_0.5.1        readr_1.3.1          munsell_0.5.0       
## [28] compiler_3.6.1       xfun_0.8             pkgconfig_2.0.3     
## [31] base64enc_0.1-3      tensorflow_2.0.0     htmltools_0.3.6     
## [34] tidyselect_1.0.0     tibble_2.99.99.9014  bookdown_0.13       
## [37] quadprog_1.5-7       randomForest_4.6-14  fansi_0.4.1         
## [40] viridisLite_0.3.0    crayon_1.3.4         withr_2.1.2         
## [43] rappdirs_0.3.1       grid_3.6.1           Quandl_2.10.0       
## [46] jsonlite_1.6.1       gtable_0.3.0         lifecycle_0.1.0     
## [49] magrittr_1.5         scales_1.0.0         rlist_0.4.6.1       
## [52] cli_2.0.1            stringi_1.4.3        xml2_1.2.2          
## [55] ellipsis_0.3.0       generics_0.0.2       vctrs_0.2.99.9005   
## [58] tools_3.6.1          glue_1.3.1           hms_0.5.1           
## [61] yaml_2.2.0           colorspace_1.4-1     rvest_0.3.4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning (XGBoost) Time-Series Classification Trading Strategy</title>
      <link>/post/xgboost-time-series-classification-trading-strategy/XGBoost-time-series-quant-trading-strategy/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/xgboost-time-series-classification-trading-strategy/XGBoost-time-series-quant-trading-strategy/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Using Machine Learning (ML) and past price data to predict the next periods price or direction in the stock market is not new, neither does it produce any meaningful predictions. In this post I &lt;em&gt;collapse&lt;/em&gt; down a series of asset time series data into a simple classification problem and see if a Machine Learning model can do a better job at predicting the next periods direction. I apply a similar method here &lt;a href=&#34;https://lf0.com/post/synth-real-time-series/financial-time-series/&#34;&gt;Time Series Classification Synthetic vs Real Financial Time Series&lt;/a&gt;. The &lt;strong&gt;objective&lt;/strong&gt; and &lt;strong&gt;strategy&lt;/strong&gt; is to invest in a single asset each day. The asset we invest in will be the asset which the Machine Learning model is most &lt;em&gt;confident&lt;/em&gt; will go up in share value in the next period &lt;span class=&#34;math inline&#34;&gt;\(t+1\)&lt;/span&gt;. Alternatively speaking, we invest in the asset in which the Machine Learning model gives the highest predicted probability that, a given asset will go up in value tomorrow. That is, if the model predicts on day &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; that asset GOOG was going to be higher than it’s previous close with a predicted probability of 0.78 and it also predicts that AMZN would go up with 0.53 probability then we would invest in GOOG today. -&lt;em&gt;we only invest in one asset each day&lt;/em&gt;- . The model can be expanded to short selling and multi-asset purchasing and multi-periods.&lt;/p&gt;
&lt;div id=&#34;load-in-the-packages.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load in the packages.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;require(PerformanceAnalytics)
library(data.table)
library(dplyr)
library(tibble)
library(TTR)
library(tidyr)
library(tidyquant)
library(tsfeatures)
library(rsample)
library(purrr)
library(stringr)
library(tibbletime) # tsibble clashes with the base R index() function
library(xgboost)
library(rvest)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pre-define a few intialisation objects and set the ticker symbols of the companies we want to download. For this task I am not really interested in which companies I apply the strategy to. For this reason, I scrape the Wikipedia page for the S&amp;amp;P 500 and take a random sample of 30 tickers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
###################### Pre-define functions for later ##########################

Scale_Me &amp;lt;- function(x){
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}                                  # Note: I don&amp;#39;t actually use this function but I leave it in here.

#################################################################################

start_date &amp;lt;- &amp;quot;2017-01-01&amp;quot;
end_date &amp;lt;- &amp;quot;2020-01-01&amp;quot;

url &amp;lt;- &amp;quot;https://en.wikipedia.org/wiki/List_of_S%26P_500_companies&amp;quot;
symbols &amp;lt;- url %&amp;gt;%
  read_html() %&amp;gt;%
  html_nodes(xpath = &amp;#39;//*[@id=&amp;quot;constituents&amp;quot;]&amp;#39;) %&amp;gt;% 
  html_table() %&amp;gt;% 
  .[[1]] %&amp;gt;% 
  filter(!str_detect(Security, &amp;quot;Class A|Class B|Class C&amp;quot;)) %&amp;gt;%     # Removes firms with Class A, B &amp;amp; C shares
  sample_n(30) %&amp;gt;% 
  pull(Symbol)


#symbols &amp;lt;- c(
  #&amp;#39;GOOG&amp;#39;, &amp;#39;MSFT&amp;#39;, &amp;#39;HOG&amp;#39;, &amp;#39;AAPL&amp;#39;, &amp;#39;FB&amp;#39; 
  #&amp;#39;AMZN&amp;#39;, &amp;#39;EBAY&amp;#39;, &amp;#39;IBM&amp;#39;, &amp;#39;NFLX&amp;#39;, &amp;#39;NVDA&amp;#39;,
  #&amp;#39;TWTR&amp;#39;, &amp;#39;WMT&amp;#39;, &amp;#39;XRX&amp;#39;, &amp;#39;INTC&amp;#39;, &amp;#39;HPE&amp;#39;
# )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The data&lt;/h2&gt;
&lt;p&gt;Download the data and store it into a new environment.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataEnv &amp;lt;- new.env()
getSymbols(symbols, 
           from = start_date, 
           to = end_date, 
           #src = &amp;quot;yahoo&amp;quot;, 
           #adjust = TRUE, 
           env = dataEnv)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;LEG&amp;quot;  &amp;quot;NLSN&amp;quot; &amp;quot;SLB&amp;quot;  &amp;quot;CHTR&amp;quot; &amp;quot;C&amp;quot;    &amp;quot;REGN&amp;quot; &amp;quot;CCI&amp;quot;  &amp;quot;SYK&amp;quot;  &amp;quot;ROP&amp;quot;  &amp;quot;RL&amp;quot;  
## [11] &amp;quot;CERN&amp;quot; &amp;quot;CMG&amp;quot;  &amp;quot;GS&amp;quot;   &amp;quot;CAT&amp;quot;  &amp;quot;MSI&amp;quot;  &amp;quot;BR&amp;quot;   &amp;quot;VRSK&amp;quot; &amp;quot;PNC&amp;quot;  &amp;quot;KEYS&amp;quot; &amp;quot;PHM&amp;quot; 
## [21] &amp;quot;FB&amp;quot;   &amp;quot;BKR&amp;quot;  &amp;quot;ABMD&amp;quot; &amp;quot;WYNN&amp;quot; &amp;quot;DG&amp;quot;   &amp;quot;ADI&amp;quot;  &amp;quot;GL&amp;quot;   &amp;quot;TSCO&amp;quot; &amp;quot;FLS&amp;quot;  &amp;quot;CDW&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the data has been downloaded and stored into a new environment I clean the data up a little, put all the lists into a single data frame, compute the daily returns for each asset and create the &lt;em&gt;up&lt;/em&gt; or &lt;em&gt;down&lt;/em&gt; direction which will be what the classification model will try to predict.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- eapply(dataEnv, function(x){
  as.data.frame(x) %&amp;gt;% 
    rename_all(function(n){
      gsub(&amp;quot;^(\\w+)\\.&amp;quot;, &amp;quot;&amp;quot;, n, perl = TRUE)
    }
    ) %&amp;gt;%
    rownames_to_column(&amp;quot;date&amp;quot;)  
}) %&amp;gt;% 
  rbindlist(idcol = TRUE) %&amp;gt;% 
  mutate(date = as.Date(date)) %&amp;gt;% 
  group_by(.id) %&amp;gt;% 
  tq_mutate(
    select = Adjusted,
    mutate_fun = periodReturn,
    period = &amp;quot;daily&amp;quot;,
    type = &amp;quot;arithmetic&amp;quot;
  ) %&amp;gt;% 
  mutate(
    Adj_lag = lag(Adjusted),
    chng_Adj = ifelse(Adjusted &amp;gt; Adj_lag, 1, 0) # more simply we could have just done if ret were pos/neg
  ) %&amp;gt;% 
  select(&amp;quot;date&amp;quot;, &amp;quot;.id&amp;quot;, &amp;quot;Adjusted&amp;quot;, &amp;quot;daily.returns&amp;quot;, &amp;quot;chng_Adj&amp;quot;, &amp;quot;Open&amp;quot;, &amp;quot;High&amp;quot;, &amp;quot;Low&amp;quot;, &amp;quot;Close&amp;quot;) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  as_tbl_time(index = date) %&amp;gt;% 
  setNames(c(&amp;quot;date&amp;quot;, &amp;quot;ID&amp;quot;, &amp;quot;prc&amp;quot;, &amp;quot;ret&amp;quot;, &amp;quot;chng&amp;quot;, &amp;quot;open&amp;quot;, &amp;quot;high&amp;quot;, &amp;quot;low&amp;quot;, &amp;quot;close&amp;quot;)) %&amp;gt;% 
  drop_na(chng)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first few observations of the data looks like:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
ID
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
prc
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ret
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
chng
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
open
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
high
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
low
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
close
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2017-01-04
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50.63446
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0162981
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52.60
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.79
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52.38
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2017-01-05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50.14147
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0097364
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52.66
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.84
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.87
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2017-01-06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49.96746
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0034704
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.95
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.46
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
51.69
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can use the &lt;code&gt;nest()&lt;/code&gt; function to put the data into convenient nested tibbles that we can simply &lt;code&gt;map()&lt;/code&gt; over and apply the &lt;code&gt;rolling_origin()&lt;/code&gt; function from the &lt;code&gt;rsample&lt;/code&gt; package such that, each of our assets will have their own &lt;code&gt;rolling_origin()&lt;/code&gt; function applied to it without any overlap or mixing of the asset classes, I do this in order to create the time series features for each period.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nested_df &amp;lt;- df %&amp;gt;%
  mutate(duplicate_ID = ID) %&amp;gt;% 
  nest(-ID)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I split the time series data into a number of lists such that the &lt;code&gt;analysis()&lt;/code&gt; list contains 100 observations in each list and has a corresponding &lt;code&gt;assessment()&lt;/code&gt; list which contains 1 observation. Usually the &lt;code&gt;analysis()&lt;/code&gt; will become our training data set and the &lt;code&gt;assessment()&lt;/code&gt; will become our testing data set, however, here I am using the &lt;code&gt;rolling_origin()&lt;/code&gt; function to help create the time series features.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First we set the number of days we want to construct the ts features
rolled_df &amp;lt;- map(nested_df$data, ~ rolling_origin(.,
                                                  initial = 100,
                                                  assess = 1,
                                                  cumulative = FALSE,
                                                  skip = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;time-series-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Time-Series Functions&lt;/h2&gt;
&lt;p&gt;In order to create the time series variables I use the &lt;code&gt;tsfeatures&lt;/code&gt; package but there is also the &lt;code&gt;feasts&lt;/code&gt; packages &lt;a href=&#34;http://feasts.tidyverts.org/&#34;&gt;here&lt;/a&gt;. For this model I simply select a few functions of interest from the &lt;code&gt;tsfeatures&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;functions &amp;lt;- c(
  &amp;quot;entropy&amp;quot;,                   # Measures the &amp;quot;forecastability&amp;quot; of a series - low values = high sig-to-noise, large vals = difficult to forecast
  &amp;quot;stability&amp;quot;,                 # means/variances are computed for all tiled windows - stability is the variance of the means
  &amp;quot;lumpiness&amp;quot;,                 # Lumpiness is the variance of the variances
  &amp;quot;max_level_shift&amp;quot;,           # Finds the largest mean shift between two consecutive windows (returns two values, size of shift and time index of shift)
  &amp;quot;max_var_shift&amp;quot;,             # Finds the max variance shift between two consecutive windows (returns two values, size of shift and time index of shift)
  &amp;quot;max_kl_shift&amp;quot;,              # Finds the largest shift in the Kulback-Leibler divergence between two consecutive windows (returns two values, size of shift and time index of shift)
  &amp;quot;crossing_points&amp;quot;            # Number of times a series crosses the mean line
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wrote this code a little while ago and at the time I wrapped the model into a function. I think it would be more fun to exclusively stick to using just &lt;code&gt;map()&lt;/code&gt; functions instead of &lt;code&gt;function(SYMB)&lt;/code&gt;. The function does the following for each asset in our data:&lt;/p&gt;
&lt;p&gt;Using the out-of-sample &lt;code&gt;t+1&lt;/code&gt; (&lt;code&gt;assessment&lt;/code&gt;) data, bind these lists together into a single data frame. Next apply the &lt;code&gt;functions&lt;/code&gt; character string to call the functions from the &lt;code&gt;tsfeatures&lt;/code&gt; package, apply these functions to the in-sample (&lt;code&gt;analysis&lt;/code&gt;) data (which consists of 100 observations each), such that, we obtain a single &lt;em&gt;collapsed&lt;/em&gt; down observation that we can just bind together. Finally we bind the columns of these two data sets together using &lt;code&gt;bind_cols()&lt;/code&gt;. After this I rename the &lt;code&gt;chng&lt;/code&gt; variable and rename the time series feature variables to something more dynamic using &lt;code&gt;~str_c(&#34;X&#34;, seq_along(.))&lt;/code&gt; so we can just add functions to the &lt;code&gt;functions&lt;/code&gt; character string and not have to worry about renaming the variables individually in order for the model to work.&lt;/p&gt;
&lt;p&gt;Once this is done, I create the Machine Learning data set again using the &lt;code&gt;rolling_origin()&lt;/code&gt; function. The first &lt;code&gt;rolling_origin()&lt;/code&gt; function was used to help &lt;em&gt;collapse&lt;/em&gt; the time series data down on a rolling basis by taking the previous 100 days of data and calculating the &lt;code&gt;tsfeatures&lt;/code&gt; function on it - &lt;em&gt;a similar method to calculating a rolling mean/sd using the &lt;code&gt;rollapply()&lt;/code&gt; function from the &lt;code&gt;zoo&lt;/code&gt; package&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I next split the data into &lt;code&gt;X&lt;/code&gt; variables with &lt;code&gt;X_train&lt;/code&gt; and &lt;code&gt;X_test&lt;/code&gt; and the corresponding &lt;code&gt;Y&lt;/code&gt; variable with &lt;code&gt;Y_train&lt;/code&gt; and &lt;code&gt;Y_test&lt;/code&gt;. The package &lt;code&gt;xgboost&lt;/code&gt; expects a certain type of &lt;code&gt;xgb.DMatrix()&lt;/code&gt; which is what &lt;code&gt;dtrain&lt;/code&gt; and &lt;code&gt;dtest&lt;/code&gt; are doing.&lt;/p&gt;
&lt;p&gt;Then, I set the XGBoost parameters and apply the XGBoost model. - &lt;em&gt;Suitable cross validation should be performed at this point, however I will leave this for another post since time series cross validation is quite tricky and there is no function in R which helps with this type of cross validation (that I have found as of 2020-02-02)&lt;/em&gt; -&lt;/p&gt;
&lt;p&gt;Once the model has been trained, I make the predictions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;apply-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Apply the model&lt;/h2&gt;
&lt;p&gt;The function to compute all this is the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Prediction_Model &amp;lt;- function(SYMB){
  data &amp;lt;- bind_cols(
    map(rolled_df[[SYMB]]$splits, ~ assessment(.x)) %&amp;gt;%
      bind_rows(),
    map(rolled_df[[SYMB]]$splits, ~ analysis(.x)) %&amp;gt;%
      map(., ~tsfeatures(.x[[&amp;quot;ret&amp;quot;]], functions)) %&amp;gt;%          # Compute the TSFeatures
      bind_rows()
  ) %&amp;gt;%
    rename(Y = chng) %&amp;gt;%
    rename_at(vars(-c(1:9)), ~str_c(&amp;quot;X&amp;quot;, seq_along(.)))        
  
  ml_data &amp;lt;- data %&amp;gt;% 
    as_tibble() %&amp;gt;% 
    rolling_origin(
      initial    = 200,
      assess     = 1,
      cumulative = FALSE,
      skip       = 0)
  
  X_train &amp;lt;- map(
    ml_data$splits, ~ analysis(.x) %&amp;gt;%
      as_tibble(., .name_repair = &amp;quot;universal&amp;quot;) %&amp;gt;%
      select(starts_with(&amp;quot;X&amp;quot;)) %&amp;gt;% 
      as.matrix()
  )
  
  Y_train &amp;lt;- map(
    ml_data$splits, ~ analysis(.x) %&amp;gt;%
      as_tibble(., .name_repair = &amp;quot;universal&amp;quot;) %&amp;gt;%
      select(starts_with(&amp;quot;Y&amp;quot;)) %&amp;gt;% 
      as.matrix()
  )
  
  X_test &amp;lt;- map(
    ml_data$splits, ~ assessment(.x) %&amp;gt;%
      as_tibble(., .name_repair = &amp;quot;universal&amp;quot;) %&amp;gt;%
      select(starts_with(&amp;quot;X&amp;quot;)) %&amp;gt;% 
      as.matrix()
  )
  
  Y_test &amp;lt;- map(
    ml_data$splits, ~ assessment(.x) %&amp;gt;%
      as_tibble(., .name_repair = &amp;quot;universal&amp;quot;) %&amp;gt;%
      select(starts_with(&amp;quot;Y&amp;quot;)) %&amp;gt;% 
      as.matrix()
  )
  
  #############################################################
  
  dtrain &amp;lt;- map2(
    X_train, Y_train, ~ xgb.DMatrix(data = .x, label = .y, missing = &amp;quot;NaN&amp;quot;)
  )
  
  dtest &amp;lt;- map(
    X_test, ~ xgb.DMatrix(data = .x, missing = &amp;quot;NaN&amp;quot;)
  )
  
  # Parameters:
  watchlist &amp;lt;- list(&amp;quot;train&amp;quot; = dtrain)
  params &amp;lt;- list(&amp;quot;eta&amp;quot; = 0.1, &amp;quot;max_depth&amp;quot; = 5, &amp;quot;colsample_bytree&amp;quot; = 1, &amp;quot;min_child_weight&amp;quot; = 1, &amp;quot;subsample&amp;quot;= 1,
                 &amp;quot;objective&amp;quot;=&amp;quot;binary:logistic&amp;quot;, &amp;quot;gamma&amp;quot; = 1, &amp;quot;lambda&amp;quot; = 1, &amp;quot;alpha&amp;quot; = 0, &amp;quot;max_delta_step&amp;quot; = 0,
                 &amp;quot;colsample_bylevel&amp;quot; = 1, &amp;quot;eval_metric&amp;quot;= &amp;quot;auc&amp;quot;,
                 &amp;quot;set.seed&amp;quot; = 176)
  
  # Train the XGBoost model
  xgb.model &amp;lt;- map(
    dtrain, ~ xgboost(params = params, data = .x, nrounds = 10, watchlist)
  )
  
  xgb.pred &amp;lt;- map2(
    .x = xgb.model, 
    .y = dtest, 
    .f = ~ predict(.x, newdata = .y, type = &amp;#39;prob&amp;#39;)
  )
  
  preds &amp;lt;- cbind(plyr::ldply(xgb.pred, data.frame),
                 plyr::ldply(Y_test, data.frame)) %&amp;gt;% 
    setNames(c(&amp;quot;pred_probs&amp;quot;, &amp;quot;actual&amp;quot;)) %&amp;gt;% 
    bind_cols(plyr::ldply(map(ml_data$splits, ~assessment(.x)))) %&amp;gt;% 
    rename(ID = duplicate_ID) %&amp;gt;% 
    #select(pred_probs, actual, date, ID, prc, ret) %&amp;gt;% 
    as_tibble()
  return(preds)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can apply the above model to create the time series features, train and test on each of our assets by running the following.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Sys_t_start &amp;lt;- Sys.time()
Resultados &amp;lt;- lapply(seq(1:length(rolled_df)), Prediction_Model)
Sys_t_end &amp;lt;- Sys.time()
round(Sys_t_end - Sys_t_start, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;Resultados&lt;/code&gt; output will give us a list the length of the number of assets we have in our data. The first few observations of the first asset in the list looks like:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
pred_probs
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
actual
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
prc
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ret
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Y
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
open
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
high
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
low
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
close
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
ID
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X2
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X3
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X4
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X5
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X6
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X7
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X8
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X9
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X10
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7304490
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73.17622
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0106061
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74.63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9870653
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1149955
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7047308
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.277064
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.161538
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.245055
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5149571
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74.35286
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0160795
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74.78
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.99
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73.04
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.83
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9886519
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0745409
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8408280
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.273320
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.143027
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.227452
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.6207952
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72.53889
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0243967
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.35
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73.45
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73.98
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9902178
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0901013
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7192391
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.275344
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.153024
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.227452
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
55
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Which consist of the XGBoost predicted probabilities, the actual observed result, the date of the result (of the out-of-sample testing data), the observed share price, the calculated daily returns, (a duplicate of the observed result), the OHLC data we collected from Yahoo and finally the time series features we constructed and then reneamed to &lt;span class=&#34;math inline&#34;&gt;\(X_{n}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;objective&lt;/strong&gt; of this strategy was to invest every day in the asset which obtained the highest predicted probability that the market was going to go up. That is, if the model predicts on day &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; that asset &lt;code&gt;GOOG&lt;/code&gt; was going to be higher than it’s previous close with a predicted probability of 0.78 and it also predicts that &lt;code&gt;AMZN&lt;/code&gt; would go up with 0.53 probability then we would invest in &lt;code&gt;GOOG&lt;/code&gt; today. That is, we only invest in the asset with the highest predicted probability that the market is going to go up.&lt;/p&gt;
&lt;p&gt;Therefore, I create a new data frame called &lt;code&gt;top_assets&lt;/code&gt; which basically gives me the highest predicted probability across all assets each day.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_assets &amp;lt;- plyr::ldply(Resultados) %&amp;gt;% 
  #select(pred_probs, actual, date, open, high, low, close, prc, ret) %&amp;gt;% 
  group_by(date) %&amp;gt;%
  arrange(desc(pred_probs)) %&amp;gt;%
  dplyr::slice(1) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  select(date, everything()) %&amp;gt;% 
  rename(score = pred_probs) %&amp;gt;% 
  select(-actual)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;strategy-assessment&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Strategy Assessment&lt;/h2&gt;
&lt;p&gt;The first 10 days of the strategy investments look like:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
score
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
prc
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ret
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Y
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
open
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
high
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
low
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
close
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
ID
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X2
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X3
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X4
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X5
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X6
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X7
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X8
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X9
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
X10
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7304490
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73.17622
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0106061
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
75.51
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74.18
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
74.63
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9870653
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1149955
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7047308
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.2770644
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.161538
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.245055
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.6899720
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
293.04999
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0051601
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
295.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
297.61
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
289.27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
293.05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ABMD
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9918187
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0769474
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.4417643
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0584676
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.917599
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.861935
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
39
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-19
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7299674
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
101.46883
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0081591
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
108.98
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
109.06
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
107.40
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
108.19
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CCI
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9894902
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0705445
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3788407
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9924987
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.786445
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.402126
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
89
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
46
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7370850
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60.44966
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0132920
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
66.10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65.56
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
SLB
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9830999
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1717591
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1725298
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.1379607
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.853699
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.739650
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
47
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7003193
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
334.51999
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0448199
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
320.94
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
339.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
320.32
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
334.52
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CMG
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9532525
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0669860
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.4899030
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.6249110
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.775679
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
73
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
12.454513
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-22
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7438304
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
87.40306
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0243534
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
91.53
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
92.43
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90.48
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
90.54
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ADI
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9796797
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0855250
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8606480
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.4206984
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.718067
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.589078
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.6494384
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
237.70613
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0290578
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
253.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
253.99
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
244.93
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
245.26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
GS
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9685330
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0615987
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7610257
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.1137175
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.588928
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
58
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.667287
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.6868502
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70.18565
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0238877
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70.74
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
71.58
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9885363
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1109430
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5278402
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.1776141
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
64
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.688307
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.038961
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7274348
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57.21453
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0020772
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
58.13
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
58.41
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57.16
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57.65
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CERN
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9787359
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1971365
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2600627
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0608221
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.325379
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.115355
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2018-03-28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7031060
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
68.56778
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0039882
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
70.39
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69.26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
69.93
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CDW
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9869206
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1328377
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5033828
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.1567020
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.593677
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
54
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.010604
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
67
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
56
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can see that the column &lt;code&gt;score&lt;/code&gt; is the probability for the asset with the highest predicted probability that it’s price was going to be greater than it’s previous close. The &lt;code&gt;ID&lt;/code&gt; column gives us the asset ticker we invest in.&lt;/p&gt;
&lt;p&gt;Next I want to analyse the strategy of picking the &lt;em&gt;best&lt;/em&gt; predicted winners against the S&amp;amp;P500 bench mark and therefore download the S&amp;amp;P 500 index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_assets &amp;lt;- xts(top_assets[,c(2:ncol(top_assets))], order.by = top_assets$date) # put top_assets into xts format

# Analyse strategy
getSymbols(&amp;quot;SPY&amp;quot;, 
           from = start_date, 
           to = end_date, 
           src = &amp;quot;yahoo&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;SPY&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#detach(&amp;quot;package:tsibble&amp;quot;, unload = TRUE) # tsibble clashes with the base R index() function
SPY$ret_Rb &amp;lt;- Delt(SPY$SPY.Adjusted)
SPY &amp;lt;- SPY[index(SPY) &amp;gt;= min(index(top_assets))]

RaRb &amp;lt;- cbind(top_assets, SPY)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here we can see how the strategy compares with the S&amp;amp;P 500. I show a number of statistics for analysing asset returns from the &lt;code&gt;PerformanceAnalytics&lt;/code&gt; package. I have not expanded the model to include short selling or construct multi-asset portfolios of the top &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; assets.&lt;/p&gt;
&lt;p&gt;We can plot the performance of our strategy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;charts.PerformanceSummary(RaRb[, c(&amp;quot;ret&amp;quot;, &amp;quot;ret_Rb&amp;quot;)], geometric = FALSE, wealth.index = FALSE, 
                          main = &amp;quot;Strategy vs. Market&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/xgboost-time-series-classification-trading-strategy/XGBoost-time-series-quant-trading-strategy_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Take a look at the drawdown and risk metrics.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##                             ret ret_Rb
## Sterling ratio           0.1870 0.3879
## Calmar ratio             0.2551 0.5884
## Burke ratio              0.2251 0.5344
## Pain index               0.0955 0.0283
## Ulcer index              0.1189 0.0455
## Pain ratio               0.7337 4.0290
## Martin ratio             0.5891 2.5027
## daily downside risk      0.0111 0.0066
## Annualised downside risk 0.1768 0.1044
## Downside potential       0.0054 0.0029
## Omega                    1.0722 1.1601
## Sortino ratio            0.0351 0.0714
## Upside potential         0.0058 0.0034
## Upside potential ratio   0.7027 0.6124
## Omega-sharpe ratio       0.0722 0.1601&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Take a closer look at the drawdown information.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## $ret
##         From     Trough         To   Depth Length To Trough Recovery
## 1 2018-08-31 2019-01-03 2019-09-16 -0.2746    261        85      176
## 2 2019-11-06 2019-12-03       &amp;lt;NA&amp;gt; -0.1300     39        19       NA
## 3 2019-10-01 2019-10-18 2019-10-29 -0.0810     21        14        7
## 4 2018-03-22 2018-04-20 2018-05-09 -0.0773     34        21       13
## 5 2018-08-10 2018-08-15 2018-08-20 -0.0474      7         4        3
## 
## $ret_Rb
##         From     Trough         To   Depth Length To Trough Recovery
## 1 2018-09-21 2018-12-24 2019-04-12 -0.1935    140        65       75
## 2 2019-05-06 2019-06-03 2019-06-20 -0.0662     33        20       13
## 3 2018-03-15 2018-04-02 2018-06-04 -0.0610     56        12       44
## 4 2019-07-29 2019-08-05 2019-10-25 -0.0602     64         6       58
## 5 2018-06-13 2018-06-27 2018-07-09 -0.0300     18        11        7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compare the returns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;chart.Boxplot(RaRb[,c(&amp;quot;ret&amp;quot;, &amp;quot;ret_Rb&amp;quot;)],  main = &amp;quot;Returns&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/xgboost-time-series-classification-trading-strategy/XGBoost-time-series-quant-trading-strategy_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Compare return statistics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table.Stats(RaRb[, c(&amp;quot;ret&amp;quot;, &amp;quot;ret_Rb&amp;quot;)]) %&amp;gt;% 
  t() %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Observations
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NAs
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Minimum
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Quartile 1
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Median
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Arithmetic Mean
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Geometric Mean
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Quartile 3
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Maximum
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SE Mean
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
LCL Mean (0.95)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
UCL Mean (0.95)
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Variance
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Stdev
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Skewness
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Kurtosis
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ret
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
453
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0669
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0068
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0003
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0087
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0642
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0007
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0011
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0018
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0156
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2542
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.8842
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ret_Rb
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
453
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0324
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0030
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0005
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0054
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0505
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0013
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0091
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2949
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.6264
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Compare Sharpe Information.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lapply(RaRb[, c(&amp;quot;ret&amp;quot;, &amp;quot;ret_Rb&amp;quot;)], function(x){SharpeRatio(x)})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $ret
##                                       ret
## StdDev Sharpe (Rf=0%, p=95%): 0.025027498
## VaR Sharpe (Rf=0%, p=95%):    0.015346462
## ES Sharpe (Rf=0%, p=95%):     0.009618405
## 
## $ret_Rb
##                                   ret_Rb
## StdDev Sharpe (Rf=0%, p=95%): 0.05152014
## VaR Sharpe (Rf=0%, p=95%):    0.03218952
## ES Sharpe (Rf=0%, p=95%):     0.01913213&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plot the Risk - Return scatter plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;chart.RiskReturnScatter(RaRb[, c(&amp;quot;ret&amp;quot;, &amp;quot;ret_Rb&amp;quot;)],  # check this plot a little more
                        Rf=.03/252, scale = 252, # for daily data
                        main = &amp;quot;Risk - Return over the period&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/xgboost-time-series-classification-trading-strategy/XGBoost-time-series-quant-trading-strategy_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Plot the rolling return, risk and Sharpe performance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;charts.RollingPerformance(RaRb[, c(&amp;quot;ret&amp;quot;, &amp;quot;ret_Rb&amp;quot;)],      
                          Rf=.03/12, 
                          colorset = c(&amp;quot;red&amp;quot;, rep(&amp;quot;darkgray&amp;quot;,5), &amp;quot;orange&amp;quot;, &amp;quot;green&amp;quot;), lwd = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/xgboost-time-series-classification-trading-strategy/XGBoost-time-series-quant-trading-strategy_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Compute the yearly returns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lapply(RaRb[, c(&amp;quot;ret&amp;quot;)],function(x){periodReturn(
  x, period = &amp;#39;yearly&amp;#39;, type = &amp;#39;arithmetic&amp;#39;)})        # change type to log for continuous&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $ret
##            yearly.returns
## 2018-12-31      -1.855083
## 2019-12-31      -1.475181&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lapply(RaRb[, c(&amp;quot;ret_Rb&amp;quot;)],function(x){periodReturn(
  x, period = &amp;#39;yearly&amp;#39;, type = &amp;#39;arithmetic&amp;#39;)})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $ret_Rb
##            yearly.returns
## 2018-12-31     -9.0376638
## 2019-12-31     -0.7226497&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Quantitative Analytics: Optimal Portfolio Allocation</title>
      <link>/post/portfolio-optimisation-model/portfolio-optimisation-R/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/portfolio-optimisation-model/portfolio-optimisation-R/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level1 tabset tabset-fade tabset-pills&#34;&gt;
&lt;h1&gt;Introduction:&lt;/h1&gt;
&lt;p&gt;The literature in portfolio optimisation has been around for decades. In this post I cover a number of traditional portfolio optimisation models. The general aim is to select a portfolio of assets out of a set of all possible portfolios being considered with a defined objective function.&lt;/p&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The data:&lt;/h2&gt;
&lt;p&gt;The data is collected using the &lt;code&gt;tidyquant()&lt;/code&gt; package’s &lt;code&gt;tq_get()&lt;/code&gt; function. I then convert the daily asset prices to daily log returns using the &lt;code&gt;periodReturn&lt;/code&gt; function from the &lt;code&gt;quantmod()&lt;/code&gt; package. Next I construct &lt;code&gt;lists&lt;/code&gt; of 6 months worth of daily returns using the &lt;code&gt;rolling_origin()&lt;/code&gt; function from the &lt;code&gt;rsample()&lt;/code&gt; package. The objective is to compute on a rolling basis the 6 month mean returns &lt;code&gt;mus&lt;/code&gt; and the 6 month covariance matrices &lt;code&gt;Sigmas&lt;/code&gt; on the training sets (i.e. 6 months) and apply them on the test sets (i.e. 1 month later) - monthly rebalancing.&lt;/p&gt;
&lt;p&gt;Just as with the returns data, the same is applied to the monthly prices data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;start_date &amp;lt;- &amp;quot;2013-01-01&amp;quot;
end_date &amp;lt;- &amp;quot;2017-08-31&amp;quot;
symbols &amp;lt;- c(&amp;quot;AAPL&amp;quot;, &amp;quot;ABBV&amp;quot;, &amp;quot;A&amp;quot;,  &amp;quot;APD&amp;quot;, &amp;quot;AA&amp;quot;, &amp;quot;CF&amp;quot;, &amp;quot;NVDA&amp;quot;, &amp;quot;HOG&amp;quot;, &amp;quot;WMT&amp;quot;, &amp;quot;AMZN&amp;quot;
            #,&amp;quot;MSFT&amp;quot;, &amp;quot;F&amp;quot;, &amp;quot;INTC&amp;quot;, &amp;quot;ADBE&amp;quot;, &amp;quot;AMG&amp;quot;, &amp;quot;AKAM&amp;quot;, &amp;quot;ALB&amp;quot;, &amp;quot;ALK&amp;quot;
            )

portfolio_prices &amp;lt;- tq_get(
  symbols,
  from = start_date,
  to = end_date,
) %&amp;gt;% 
  select(symbol, date, adjusted)


portfolio_monthly_returns &amp;lt;- portfolio_prices %&amp;gt;% 
  group_by(symbol) %&amp;gt;% 
  tq_transmute(
    select = adjusted,
    mutate_fun = periodReturn,
    period = &amp;quot;daily&amp;quot;,                              
    type = &amp;quot;log&amp;quot;,
  ) %&amp;gt;% 
  pivot_wider(names_from = symbol, values_from = daily.returns) %&amp;gt;% 
  mutate(year_month = yearmonth(date)) %&amp;gt;% 
  nest(-year_month) %&amp;gt;% 
  rolling_origin(
    initial = 6,
    assess = 1,
    skip = 0,
    cumulative = FALSE)


portfolio_monthly_prices &amp;lt;- portfolio_prices %&amp;gt;%
  pivot_wider(names_from = symbol, values_from = adjusted) %&amp;gt;% 
  mutate(year_month = yearmonth(date)) %&amp;gt;% 
  nest(-year_month) %&amp;gt;% 
  rolling_origin(
    initial = 6,
    assess = 1,
    skip = 0,
    cumulative = FALSE)

ListNamesDates &amp;lt;- map(portfolio_monthly_returns$splits, ~assessment(.x) %&amp;gt;%
                        select(year_month)) %&amp;gt;%
  plyr::ldply(., data.frame) %&amp;gt;% 
  pull(year_month)

#########

# Goal is to define the mean and covariance matrix on the training sets and apply them on the test sets - monthly rebalancing

mus &amp;lt;- map(portfolio_monthly_returns$splits, ~ analysis(.x) %&amp;gt;% 
             unnest(data) %&amp;gt;%
             select(-year_month, -date) %&amp;gt;%
             colMeans) %&amp;gt;%
  setNames(c(ListNamesDates))

Sigmas &amp;lt;- map(portfolio_monthly_returns$splits, ~ analysis(.x) %&amp;gt;%
                unnest() %&amp;gt;%
                tk_xts(., date_var = date) %&amp;gt;%
                cov(.)) %&amp;gt;% 
  setNames(c(ListNamesDates))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;price-and-returns-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Price and Returns data&lt;/h2&gt;
&lt;p&gt;The returns data for the first &lt;code&gt;split&lt;/code&gt; looks like the following:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.012702708
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.008291331
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.003575412
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0035002417
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.008859253
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.004740037
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0007860485
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.020819530
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0063746748
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0045367882
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.028249939
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.012713395
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.019555411
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0133515376
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.020731797
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.022152033
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0324601827
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.005529864
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0037720098
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0025886574
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.005899428
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.002033327
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.007259372
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0009230752
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.017429792
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.003753345
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0293228286
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.006958715
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0096029606
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0352948721
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.002687379
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.022004791
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.008022622
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0018451781
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.014769161
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0221704307
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.003063936
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0027737202
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0077780140
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.015752246
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.005620792
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.026649604
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0133906716
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.002200109
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.034376623
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0226730363
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.038724890
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0002916231
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0001126237
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;the-statistics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The statistics&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;Mus&lt;/code&gt; (mean returns) data looks like:&lt;/p&gt;
&lt;table class=&#34;kable_wrapper table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AAPL
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0025241
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ABBV
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0014847
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002314
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
APD
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006546
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0010700
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0013681
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NVDA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0008864
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
HOG
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0008061
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
WMT
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006895
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AMZN
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0006147
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The &lt;code&gt;Sigmas&lt;/code&gt; (covariance matrix) data looks like:&lt;/p&gt;
&lt;table class=&#34;kable_wrapper table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AAPL
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0004166
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000220
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000112
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000388
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000528
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000277
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000408
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000116
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000038
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000366
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ABBV
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000220
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0003128
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000490
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000393
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000137
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000472
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000511
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000732
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000258
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000295
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000112
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000490
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002061
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000720
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000741
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000885
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000930
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001175
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000371
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001139
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
APD
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000388
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000393
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000720
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000993
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000523
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000687
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000578
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000744
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000107
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000511
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000528
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000137
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000741
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000523
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001485
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000874
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000685
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000674
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000012
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000383
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CF
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000277
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000472
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000885
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000687
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000874
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002271
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000706
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000900
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000112
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000606
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NVDA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000408
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000511
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000930
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000578
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000685
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000706
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002092
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000706
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000127
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000853
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
HOG
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000116
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000732
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001175
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000744
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000674
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000900
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000706
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002393
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000214
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000895
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
WMT
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000038
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000258
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000371
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000107
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000012
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000112
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000127
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000214
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000682
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000236
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AMZN
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000366
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000295
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0001139
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000511
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000383
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000606
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000853
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000895
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000236
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0003118
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparing-portfolio-optimisation&#34; class=&#34;section level1 tabset tabset-fade tabset-pills&#34;&gt;
&lt;h1&gt;Comparing Portfolio Optimisation&lt;/h1&gt;
&lt;div id=&#34;global-minimum-variance-portfolio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Global Minimum Variance Portfolio&lt;/h2&gt;
&lt;p&gt;The global minimum-variance portfolio &lt;span class=&#34;math inline&#34;&gt;\(w^{gmv}\)&lt;/span&gt; is a portfolio of assets with gives us the lowest possible return variance or portfolio volatility. Volatility here is used as a replacement for risk, thus with less variance in volatility correlates to less risk in an asset. The portfolio focuses only on risk and ignores expected returns.&lt;/p&gt;
&lt;p&gt;The objective function is;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{eqnarray} \min_{w} w^{T} \Sigma w \\
\text{subject to } 1^{T}w = 1 \\
w \ge 0 \end{eqnarray}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since &lt;span class=&#34;math inline&#34;&gt;\(\Sigma\)&lt;/span&gt; is unknown we can estimate it as &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Sigma}\)&lt;/span&gt; with the covariance matrix. In which the convex solution becomes:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[W = \dfrac{1}{1^{T}\hat{\Sigma}^{-1}1}\hat{\Sigma}^{-1}1\]&lt;/span&gt;
The objective is that we want to find the optimial weights from the model such that our risk is minimised.&lt;/p&gt;
&lt;p&gt;The below problem consists of our &lt;span class=&#34;math inline&#34;&gt;\(Minimisation\)&lt;/span&gt; problem &lt;span class=&#34;math inline&#34;&gt;\(\min_{w} w^{T} \Sigma w\)&lt;/span&gt;. The &lt;code&gt;quad_form&lt;/code&gt; function takes the quadratic form &lt;span class=&#34;math inline&#34;&gt;\(x^T Px\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is a vector and &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; is a matrix or in our case &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; is our weights vector and &lt;span class=&#34;math inline&#34;&gt;\(\Sigma\)&lt;/span&gt; is the covariance matrix for &lt;span class=&#34;math inline&#34;&gt;\(A_{1}, \dots, A_{5}\)&lt;/span&gt;. The &lt;code&gt;constraints&lt;/code&gt; correspond to &lt;span class=&#34;math inline&#34;&gt;\(1^{T}w = 1\)&lt;/span&gt; in which we cannot assign negative weights to our assets and that we invest all our capital in the portfolio.&lt;/p&gt;
&lt;p&gt;We can use the Disciplined Convex Programming (&lt;code&gt;CVXR&lt;/code&gt;) package in R, which;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Analyses the problem,&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Verifies the convexity,&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Converts the problem into canonical form,&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Solves the problem.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We want to find the optimial weights from the model such that our risk is minimised. We can do this by solving the optimisation problem, bind the lists into a single data frame and use &lt;code&gt;ggplot2&lt;/code&gt; to plot the rolling one month out of sample optimal portfolio weights - based on the previous 6 months rolled &lt;code&gt;mus&lt;/code&gt; and &lt;code&gt;Sigmas&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 1) Function: Global Minimum Variance Portfolio
GMVPportolioFunction &amp;lt;- function(Sigma) {
  w &amp;lt;- Variable(nrow(Sigma))
  problem &amp;lt;- Problem(               # Initialise the problem
    Minimize(                       # minimse or maximise objective function
      quad_form(
        w, Sigma                    # Model inputs, the number of weights to consider and the covariance matrix
        )
      ), 
    constraints = list(
      w &amp;gt;= 0,                       # First model constraint
      sum(w) == 1))                 # Second model constrain
  Solution &amp;lt;- solve(problem, solver=&amp;quot;SCS&amp;quot;)        # Solves the problem
  return(as.vector(Solution$getValue(w)))
}

# 1a) Portfolio GMVP
GMVPPortfolio &amp;lt;- map(
  .x = Sigmas,
  GMVPportolioFunction)

# 1b) Portfolio GMVP
GMVPPortfolioWeights &amp;lt;- setNames(GMVPPortfolio, ListNamesDates) %&amp;gt;% 
  map(.,  ~setNames(., c(symbols))) %&amp;gt;% 
  map_dfr(., ~bind_rows(.), .id = &amp;quot;date&amp;quot;) %&amp;gt;% 
  mutate(date = as.Date(paste(date, &amp;quot;01&amp;quot;), format = &amp;quot;%Y %b %d&amp;quot;))

GMVPPortfolioWeights %&amp;gt;%
  head() %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-07-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0600841
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0335474
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1487694
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1258906
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0727919
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0095632
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5208891
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0284642
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1046817
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0404000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000009
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0917764
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1592917
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0299732
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0364528
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5374240
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000007
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-09-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1183895
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000005
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000006
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0844453
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1683525
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0246108
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0635568
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000002
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5406430
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000004
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-10-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0975699
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0024138
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0742436
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1166938
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0431301
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0968247
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5691240
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-11-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1480922
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000003
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0620406
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0449223
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000003
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0279872
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1613034
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0376023
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5014186
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0166322
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-12-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1135468
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000007
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0678773
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0560224
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0000005
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0062812
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1195510
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0779063
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5588149
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000001
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 1c) Portfolio GMVP
GMVPPortfolioWeights %&amp;gt;% 
  select(date, everything()) %&amp;gt;% 
  pivot_longer(cols = 2:ncol(.), values_to = &amp;quot;weights&amp;quot;) %&amp;gt;% 
  ggplot(aes(fill = name, y = weights, x = date)) + 
  geom_bar(position = &amp;quot;stack&amp;quot;, stat = &amp;quot;identity&amp;quot;, width = 100) +
  scale_fill_viridis(option = &amp;quot;magma&amp;quot;, discrete = TRUE, name = &amp;quot;Asset&amp;quot;) +
  theme_bw() +
  ggtitle(&amp;quot;GMVP Rolling Portfolio Adjustments&amp;quot;) +
  xlab(&amp;quot;Date&amp;quot;) +
  ylab(&amp;quot;Weights&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;markowitz-portfolio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Markowitz Portfolio&lt;/h2&gt;
&lt;p&gt;The Markowitz Mean-Variance Portfolio is constructed as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{eqnarray} \max_{w} \mu^{T}w - \lambda w^{T}\Sigma w \\
\text{subject to } 1^{T}w = 1 \\
w \ge 0 \end{eqnarray}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can set different risk parameters by adjusting &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; and see how the returns are affected. This can be done by running multiple optimisation problems on the data with different &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values. Higher &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values places emphasis on the right hand side of the equation and thus the more risk adverse the investor is.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 2) Function: Markowitz Portfolio
MarkowitzportolioFunction &amp;lt;- function(mu, Sigma, lmd) {
  w &amp;lt;- Variable(nrow(Sigma))
  problem &amp;lt;- Problem(
    Maximize(t(mu) %*% w - lmd*quad_form(w, Sigma)),
    constraints = list(
      w &amp;gt;= 0, 
      sum(w) == 1)
  )
  Solution &amp;lt;- solve(problem)
  return(as.vector(Solution$getValue(w)))
}

# 2a) Portfolio Markowitz
lmd &amp;lt;- c(0.25, 0.5, 0.75)
MarkowitzPortfolio &amp;lt;- map(lmd,
                          ~map2(
                            .x = mus,
                            .y = Sigmas,
                            MarkowitzportolioFunction, lmd = .x))

# 2b) Portfolio Markowitz
MarkowitzPortfolioWeights &amp;lt;- setNames(MarkowitzPortfolio, lmd) %&amp;gt;% 
  map(., ~setNames(., c(ListNamesDates))) %&amp;gt;% 
  map(., ~map(., ~setNames(., c(symbols)))) %&amp;gt;% 
  map(., ~map_dfr(., ~bind_rows(.), .id = &amp;quot;date&amp;quot;)) %&amp;gt;% 
  map_dfr(., ~bind_rows(.), .id = &amp;quot;lambda&amp;quot;) %&amp;gt;% 
  mutate(date = as.Date(paste(date, &amp;quot;01&amp;quot;), format = &amp;quot;%Y %b %d&amp;quot;))

MarkowitzPortfolioWeights %&amp;gt;%
  head() %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
lambda
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-07-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2938168
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7061832
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-09-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-10-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000001
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9999984
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000001
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-11-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-12-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can see how the risk and return is affected by the changes in the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values in the following plot. As the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values increase the less risk we take on but also we assume less returns. Low values of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; makes us invest in a signle asset with the weight on asset &lt;span class=&#34;math inline&#34;&gt;\(A_{5}\)&lt;/span&gt;, increasing the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values increases the weights in other assets &lt;span class=&#34;math inline&#34;&gt;\(A_{i}\)&lt;/span&gt; spreading our risk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 2c) Portfolio Markowitz
MarkowitzPortfolioWeights %&amp;gt;% 
  select(date, lambda, everything()) %&amp;gt;% 
  pivot_longer(cols = 3:ncol(.), values_to = &amp;quot;weights&amp;quot;) %&amp;gt;% 
  ggplot(aes(fill = name, y = weights, x = date)) + 
  geom_bar(position = &amp;quot;stack&amp;quot;, stat = &amp;quot;identity&amp;quot;, width = 100) +
  facet_wrap(~lambda, ncol = 1) +
  scale_fill_viridis(option = &amp;quot;magma&amp;quot;, discrete = TRUE, name = &amp;quot;Asset&amp;quot;) +
  theme_bw() +
  ggtitle(&amp;quot;Markowitz Rolling Portfolio Adjustments&amp;quot;,
          subtitle = &amp;quot;For different Lambda Risk Values&amp;quot;) +
  xlab(&amp;quot;Date&amp;quot;) +
  ylab(&amp;quot;Weights&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;max-sharpe-ratio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Max Sharpe Ratio&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I originally made this post a few months back and when I went back to it some of the parts for the Max-Sharpe Ratio portfolio did not work as before - I think this is due to the recent update in the &lt;code&gt;tidyr&lt;/code&gt; package. I made some minor adjustments, however this part of the post is incorrect (just look at the portfolio weights plot). I hightlight in the code when I made the minor adjustments - when I have the opportunity to go back through the code more carefully I will -&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 2) Function: Max Sharpe Ratio 
#NOTE::: When we have all negative mus for a given month we obtain an NA value - the function 
# cannot find a maximum when all mus are negative compare the MaxSharpePortfolio$`2015 Sep` and
# MaxSharpePortfolio$`2015 Oct` along with the mus$`2015 Sep` and mus$`2015 Oct` we invests 99% of the portfolio
# in Sept in ABBV since its positive. In Oct ABBV mu is negative and we cannot invest at all.
# Increasing the universe of Assets may overcome this problem.
MaxSharpeportolioFunction &amp;lt;- function(mu, Sigma) {
  w &amp;lt;- Variable(nrow(Sigma))
  problem &amp;lt;- Problem(
    Minimize(quad_form(w, Sigma)),
    constraints = list(
      w &amp;gt;= 0, t(mu) %*% w == 1)
  )
  Solution &amp;lt;- solve(problem, solver=&amp;quot;SCS&amp;quot;)
  return(as.vector(Solution$getValue(w)/sum(Solution$getValue(w))))
}

# 3a) Portfolio Max Sharpe Ratio                                 
MaxSharpePortfolio &amp;lt;- purrr::map2(.x = mus,
                                  .y = Sigmas,
                                  .f = ~MaxSharpeportolioFunction(.x, .y))

# 3b) Portfolio Max Sharpe Ratio
  MaxSharpePortfolioWeights &amp;lt;- setNames(MaxSharpePortfolio, ListNamesDates) %&amp;gt;%
    as_tibble(.) %&amp;gt;%               # Made an adjustment here
    map(.,  ~setNames(., c(symbols))) %&amp;gt;% 
    map_dfr(., ~bind_rows(.), .id = &amp;quot;date&amp;quot;) %&amp;gt;% 
    mutate(date = as.Date(paste(date, &amp;quot;01&amp;quot;), format = &amp;quot;%Y %b %d&amp;quot;))

MaxSharpePortfolioWeights %&amp;gt;%
  head() %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-07-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0009088
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1532283
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0371040
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2332344
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1010233
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0126946
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2083815
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0262255
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5086221
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0269248
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0109744
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1485344
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0156878
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3292178
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0080488
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0051372
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1146053
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0091278
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4086911
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0025515
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-09-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1217206
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1246626
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0087004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3421645
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2414533
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0002820
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1610166
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-10-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0270424
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2268394
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3427932
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2653166
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1283026
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0097059
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-11-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2061379
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1890218
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2234739
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0533254
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3280410
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-12-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2252115
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0306323
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0724210
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0325004
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0000000
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1907158
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1192395
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3292796
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 3c) Portfolio Max Sharpe Ratio
MaxSharpePortfolioWeights %&amp;gt;% 
  select(date, everything()) %&amp;gt;%      # Made an adjustment here
  pivot_longer(cols = 2:ncol(.), values_to = &amp;quot;weights&amp;quot;) %&amp;gt;% 
  ggplot(aes(fill = name, y = weights, x = date)) + 
  geom_bar(position = &amp;quot;stack&amp;quot;, stat = &amp;quot;identity&amp;quot;, width = 100) +
  scale_fill_viridis(option = &amp;quot;magma&amp;quot;, discrete = TRUE, name = &amp;quot;Asset&amp;quot;) +
  theme_bw() +
  ggtitle(&amp;quot;Maximum Sharpe Ratio Rolling Portfolio Adjustments&amp;quot;) +
  xlab(&amp;quot;Date&amp;quot;) +
  ylab(&amp;quot;Weights&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mu-quintile-portfolio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mu Quintile Portfolio&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 1a)
mu_quintiles &amp;lt;- map(mus, ~ntile(., 5) %&amp;gt;% 
                      setNames(c(symbols))) %&amp;gt;% 
  map(., ~sort(., decreasing = TRUE))

# 2)       
mu_diag_sigma &amp;lt;- map2(
  .x = mus,
  .y = Sigmas,
  ~.x / diag(.y)) 

mu_diag_sigma_quintiles &amp;lt;- mu_diag_sigma %&amp;gt;% 
  map(., ~ntile(., 5)) %&amp;gt;% 
  map(., ~setNames(., c(symbols))) %&amp;gt;% 
  map(., ~sort(., decreasing = TRUE))

# 1b) rank the quintiles by mu
quintiles_mu &amp;lt;- map2(
  .x = mus,
  .y = mu_quintiles,
  ~bind_rows(.x, .y))

quintiles_mu_weights &amp;lt;- map(quintiles_mu, ~ .x %&amp;gt;%
                              mutate_all(~ case_when(. %in% c(5, 1) ~ .5, 
                                                     TRUE ~ 0)) %&amp;gt;%
                              pmap_dfr(., ~ 
                                         {v1 &amp;lt;- c(...)
                                         v2 &amp;lt;- if(sum(v1) &amp;gt; 1) replace(v1, v1 != 0, 1/sum(v1!=0)) else v1
                                         as.list(v2)}))


quintiles_mu_weights &amp;lt;- map(quintiles_mu_weights, ~.x[-1,]) %&amp;gt;% 
  map2(.x = quintiles_mu, .y = ., ~bind_rows(.x, .y))

QuintileMuWeights &amp;lt;- map(quintiles_mu_weights, ~.x[3, ]) %&amp;gt;%  # The weights are stored in row 3.
  map_dfr(., ~bind_rows(.), .id = &amp;quot;date&amp;quot;) %&amp;gt;% 
  mutate(date = as.Date(paste(date, &amp;quot;01&amp;quot;), format = &amp;quot;%Y %b %d&amp;quot;))

QuintileMuWeights %&amp;gt;%
  head() %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-07-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-09-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-10-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-11-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-12-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;QuintileMuWeights %&amp;gt;% 
    select(date, everything()) %&amp;gt;%
  pivot_longer(cols = 2:ncol(.), values_to = &amp;quot;weights&amp;quot;) %&amp;gt;% 
  ggplot(aes(fill = name, y = weights, x = date)) + 
  geom_bar(position = &amp;quot;stack&amp;quot;, stat = &amp;quot;identity&amp;quot;, width = 100) +
  scale_fill_viridis(option = &amp;quot;magma&amp;quot;, discrete = TRUE, name = &amp;quot;Asset&amp;quot;) +
  theme_bw() +
  ggtitle(&amp;quot;Quintile MU Rolling Portfolio Adjustments&amp;quot;) +
  xlab(&amp;quot;Date&amp;quot;) +
  ylab(&amp;quot;Weights&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mu-diagsigma-portfolio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mu / Diag(Sigma) Portfolio&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 2a) 
mu_diag_sigma &amp;lt;- map2(
  .x = mus,
  .y = Sigmas,
  ~.x / diag(.y)) 

mu_diag_sigma_quintiles &amp;lt;- mu_diag_sigma %&amp;gt;% 
  map(., ~ntile(., 5)) %&amp;gt;% 
  map(., ~setNames(., c(symbols))) %&amp;gt;% 
  map(., ~sort(., decreasing = TRUE))

# 2b) rank the quintiles by mu / diag(Sigma)
quintiles_mu_diag_sigma &amp;lt;- map2(
  .x = mu_diag_sigma,
  .y = mu_diag_sigma_quintiles,
  ~bind_rows(.x, .y))

quintiles_mu_diag_sigma_weights &amp;lt;- map(quintiles_mu_diag_sigma, ~ .x %&amp;gt;%
                                         mutate_all(~ case_when(. %in% c(5, 1) ~ .5, 
                                                                TRUE ~ 0)) %&amp;gt;%
                                         pmap_dfr(., ~ 
                                                    {v1 &amp;lt;- c(...)
                                                    v2 &amp;lt;- if(sum(v1) &amp;gt; 1) replace(v1, v1 != 0, 1/sum(v1!=0)) else v1
                                                    as.list(v2)}))

quintiles_mu_diag_sigma_weights &amp;lt;- map(quintiles_mu_diag_sigma_weights, ~.x[-1,]) %&amp;gt;% 
  map2(.x = quintiles_mu_diag_sigma, .y = ., ~bind_rows(.x, .y))

QuintileMuDiagSigmaWeights &amp;lt;- map(quintiles_mu_diag_sigma_weights, ~.x[3, ]) %&amp;gt;% # The weights are stored in row 3.
  map_dfr(., ~bind_rows(.), .id = &amp;quot;date&amp;quot;) %&amp;gt;% 
  mutate(date = as.Date(paste(date, &amp;quot;01&amp;quot;), format = &amp;quot;%Y %b %d&amp;quot;))

QuintileMuDiagSigmaWeights %&amp;gt;%
  head() %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-07-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-09-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-10-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-11-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-12-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;QuintileMuDiagSigmaWeights %&amp;gt;% 
  select(date, everything()) %&amp;gt;%
  pivot_longer(cols = 2:ncol(.), values_to = &amp;quot;weights&amp;quot;) %&amp;gt;% 
  ggplot(aes(fill = name, y = weights, x = date)) + 
  geom_bar(position = &amp;quot;stack&amp;quot;, stat = &amp;quot;identity&amp;quot;, width = 100) +
  scale_fill_viridis(option = &amp;quot;magma&amp;quot;, discrete = TRUE, name = &amp;quot;Asset&amp;quot;) +
  theme_bw() +
  ggtitle(&amp;quot;Quintile MU Diag Sigma Rolling Portfolio Adjustments&amp;quot;) +
  xlab(&amp;quot;Date&amp;quot;) +
  ylab(&amp;quot;Weights&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mu-diagsqrtsigma-portfolio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mu / Diag(sqrt(Sigma)) Portfolio&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 3a)
mu_diag_sqrt_sigma &amp;lt;- map2(
  .x = mus,
  .y = Sigmas,
  ~.x / sqrt(diag(.y)))  

mu_diag_sqrt_sigma_quintiles &amp;lt;- mu_diag_sqrt_sigma %&amp;gt;% 
  map(., ~ntile(., 5)) %&amp;gt;% 
  map(., ~setNames(., c(symbols))) %&amp;gt;% 
  map(., ~sort(., decreasing = TRUE))

# 3b) rank the quintiles by mu / sqrt(diag(sigma))

quintiles_mu_diag_sqrt_sigma &amp;lt;- map2(
  .x = mu_diag_sqrt_sigma,
  .y = mu_diag_sqrt_sigma_quintiles,
  ~bind_rows(.x, .y))

quintiles_mu_diag_sqrt_sigma_weights &amp;lt;- map(quintiles_mu_diag_sqrt_sigma, ~ .x %&amp;gt;%
                                         mutate_all(~ case_when(. %in% c(5, 1) ~ .5, 
                                                                TRUE ~ 0)) %&amp;gt;%
                                         pmap_dfr(., ~ 
                                                    {v1 &amp;lt;- c(...)
                                                    v2 &amp;lt;- if(sum(v1) &amp;gt; 1) replace(v1, v1 != 0, 1/sum(v1!=0)) else v1
                                                    as.list(v2)}))

quintiles_mu_diag_sqrt_sigma_weights &amp;lt;- map(quintiles_mu_diag_sqrt_sigma_weights, ~.x[-1,]) %&amp;gt;% 
  map2(.x = quintiles_mu_diag_sqrt_sigma, .y = ., ~bind_rows(.x, .y))

QuintileMuDiagSqrtSigmaWeights &amp;lt;- map(quintiles_mu_diag_sqrt_sigma_weights, ~.x[3, ]) %&amp;gt;% # The weights are stored in row 3.
  map_dfr(., ~bind_rows(.), .id = &amp;quot;date&amp;quot;) %&amp;gt;% 
  mutate(date = as.Date(paste(date, &amp;quot;01&amp;quot;), format = &amp;quot;%Y %b %d&amp;quot;))

QuintileMuDiagSqrtSigmaWeights %&amp;gt;%
  head() %&amp;gt;% 
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
date
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AAPL
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
ABBV
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
A
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
APD
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
CF
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
NVDA
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
HOG
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
WMT
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
AMZN
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-07-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-09-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-10-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-11-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-12-01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.25
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;QuintileMuDiagSqrtSigmaWeights %&amp;gt;% 
  select(date, everything()) %&amp;gt;%
  pivot_longer(cols = 2:ncol(.), values_to = &amp;quot;weights&amp;quot;) %&amp;gt;% 
  ggplot(aes(fill = name, y = weights, x = date)) + 
  geom_bar(position = &amp;quot;stack&amp;quot;, stat = &amp;quot;identity&amp;quot;, width = 100) +
  scale_fill_viridis(option = &amp;quot;magma&amp;quot;, discrete = TRUE, name = &amp;quot;Asset&amp;quot;) +
  theme_bw() +
  ggtitle(&amp;quot;Quintile MU Diag Sqrt(Sigma) Rolling Portfolio Adjustments&amp;quot;) +
  xlab(&amp;quot;Date&amp;quot;) +
  ylab(&amp;quot;Weights&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-of-results&#34; class=&#34;section level1 tabset tabset-fade tabset-pills&#34;&gt;
&lt;h1&gt;Analysis of Results&lt;/h1&gt;
&lt;p&gt;There are 8 different portfolio optimisation models. Putting all the data together, it’s easier to inspect the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;############################# Assess the Returns ##################################
MonthlyReturns &amp;lt;- map(portfolio_monthly_prices$splits, ~assessment(.x)) %&amp;gt;% 
  map(., ~unnest(.x, data) %&amp;gt;% 
        select(-year_month) %&amp;gt;% 
        tk_xts(date_var = date) %&amp;gt;% 
        lapply(., periodReturn, period = &amp;quot;monthly&amp;quot;)) %&amp;gt;% 
  setNames(., ListNamesDates) %&amp;gt;% 
  map(., ~data.frame(.)) %&amp;gt;% 
  bind_rows(., .id = &amp;quot;date&amp;quot;) %&amp;gt;% 
  mutate(date = as.Date(paste(date, &amp;quot;01&amp;quot;), format = &amp;quot;%Y %b %d&amp;quot;)) %&amp;gt;% 
  tk_xts(., date_var = date)

############# Assess the Monthly Portfolio Returns Depeninding on Weights #########

# 1d)
TS_GMVPPortfolioWeights &amp;lt;- GMVPPortfolioWeights %&amp;gt;% 
  tk_xts(., date_var = date)

PortRets_GMVP &amp;lt;- Return.portfolio(MonthlyReturns, weights = TS_GMVPPortfolioWeights) %&amp;gt;% 
  setNames(c(&amp;quot;GMVP&amp;quot;))


# 2d)
TS_MarkowitzPortfolioWeights &amp;lt;- MarkowitzPortfolioWeights %&amp;gt;% 
  group_split(lambda) %&amp;gt;% 
  setNames(c(lmd)) %&amp;gt;% 
  map(., ~tk_xts(., select = -lambda, date_var = date))

MarkowitzWeightedPortfolioReturnsFunction &amp;lt;- function(lmd){
  WeightedReturns = Return.portfolio(MonthlyReturns, weights = TS_MarkowitzPortfolioWeights[[lmd]])
  return(fortify.zoo(WeightedReturns))
}

PortRets_Markowitz &amp;lt;- lapply(seq(1:length(lmd)), MarkowitzWeightedPortfolioReturnsFunction) %&amp;gt;% 
  setNames(c(lmd)) %&amp;gt;%
  bind_rows(., .id = &amp;quot;lmd&amp;quot;) %&amp;gt;% 
  #column_to_rownames(&amp;quot;Index&amp;quot;) %&amp;gt;% 
  #select(-matches(&amp;quot;Index&amp;quot;)) %&amp;gt;% 
  #rownames_to_column(&amp;quot;Index&amp;quot;) %&amp;gt;% 
  mutate(Index = as.Date(Index),
         lmd = as.numeric(lmd)) %&amp;gt;% 
  pivot_wider(names_from = lmd, values_from = portfolio.returns) %&amp;gt;% 
  tk_xts(date_var = Index) %&amp;gt;% 
  setNames(c(paste(&amp;quot;Markowitz Lambda&amp;quot;, lmd)))

# 3d)
TS_MaxSharpePortfolioWeights &amp;lt;- MaxSharpePortfolioWeights %&amp;gt;% 
  tk_xts(., date_var = date)

PortRets_MaxSharpe &amp;lt;- Return.portfolio(MonthlyReturns, weights = TS_MaxSharpePortfolioWeights) %&amp;gt;% 
  setNames(c(&amp;quot;MaxSharpe&amp;quot;))


# 4) quintile mu

TS_QuintileMuWeights &amp;lt;- QuintileMuWeights %&amp;gt;% 
  tk_xts(., date_var = date)

PortRets_Mu_Quintiles &amp;lt;- Return.portfolio(MonthlyReturns, weights = TS_QuintileMuWeights) %&amp;gt;% 
  setNames(c(&amp;quot;Mu_Quintiles&amp;quot;))

# 4) quintile mu diag sigma

TS_QuintileMuDiagSigmaWeights &amp;lt;- QuintileMuDiagSigmaWeights %&amp;gt;% 
  tk_xts(., date_var = date)

PortRets_MuDiagSigma_Quintiles &amp;lt;- Return.portfolio(MonthlyReturns, weights = TS_QuintileMuDiagSigmaWeights) %&amp;gt;% 
  setNames(c(&amp;quot;MuDiagSigma_Quintiles&amp;quot;))

# 4) Quintile mu diga sqrt sigma

TS_QuintileMuDiagSqrtSigmaWeights &amp;lt;- QuintileMuDiagSqrtSigmaWeights %&amp;gt;% 
  tk_xts(., date_var = date)

PortRets_MuDiagSqrtSigma_Quintiles &amp;lt;- Return.portfolio(MonthlyReturns, weights = TS_QuintileMuDiagSqrtSigmaWeights) %&amp;gt;% 
  setNames(c(&amp;quot;MuDiagSqrtSigma_Quintiles&amp;quot;))

#####################################################################################&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at the plots the Global Minimum Variance Portfolio shows the lowest volatility in the portfolio returns. The Max Sharpe portfolio is clearly wrong here (see, previous point on Max Sharpe Ratio section). The annaulised performance metrics are also displayed at the bottom for each portfolio over the period.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;########## Assess the Annualised Returns based on portfolio weights ##################
AllReturns &amp;lt;- cbind(PortRets_GMVP, PortRets_Markowitz, PortRets_MaxSharpe, PortRets_Mu_Quintiles,
                    PortRets_MuDiagSigma_Quintiles, PortRets_MuDiagSqrtSigma_Quintiles)
                    
library(data.table)
AllReturns %&amp;gt;%
  data.table(keep.rownames = TRUE) %&amp;gt;%
  as_tibble() %&amp;gt;% 
  pivot_longer(cols = 2:ncol(.)) %&amp;gt;% 
  ggplot(aes(x = index, y = value, color = name)) +
  geom_line() +
  facet_wrap(~name, ncol = 2) +
  ggtitle(&amp;quot;Portfolio Returns&amp;quot;, subtitle = &amp;quot;With portfolio optimised weights&amp;quot;) +
  xlab(&amp;quot;Returns&amp;quot;) +
  ylab(&amp;quot;Date&amp;quot;) +
  theme_tq()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AnnualMetrics &amp;lt;- bind_cols(table.AnnualizedReturns(PortRets_GMVP) %&amp;gt;% 
                          rownames_to_column(&amp;quot;Metric&amp;quot;),
                        table.AnnualizedReturns(PortRets_Markowitz),
                        table.AnnualizedReturns(PortRets_MaxSharpe),
                        table.AnnualizedReturns(PortRets_Mu_Quintiles),
                        table.AnnualizedReturns(PortRets_MuDiagSigma_Quintiles),
                        table.AnnualizedReturns(PortRets_MuDiagSqrtSigma_Quintiles)
                        )

AnnualMetrics %&amp;gt;%
  kable() %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed table-responsive&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Metric
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
GMVP
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Markowitz Lambda 0.25
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Markowitz Lambda 0.5
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Markowitz Lambda 0.75
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
MaxSharpe
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Mu_Quintiles
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
MuDiagSigma_Quintiles
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
MuDiagSqrtSigma_Quintiles
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Annualized Return
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1009
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8441
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8142
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.7712
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1450
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1939
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2590
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2691
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Annualized Std Dev
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1127
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3617
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3516
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3353
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1473
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1800
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1485
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1535
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Annualized Sharpe (Rf=0%)
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8951
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.3340
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.3157
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.2999
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9845
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0774
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.7437
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.7529
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Plotting the cumulative returns shows that the Markowitz lambda portfolios have the highest returns over the period, however they also have the highest standard deviation over the same period.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;chart.CumReturns(AllReturns, main = &amp;quot;Weighted Returns by Objective Function and Risk Tolerance&amp;quot;,
                 wealth.index = TRUE, legend.loc = &amp;quot;topleft&amp;quot;, colorset = rich6equal)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;charts.PerformanceSummary(AllReturns, main = &amp;quot;Performance for Different Weighted Assets&amp;quot;, 
                          wealth.index = TRUE, colorset = rich6equal)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-20-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;additional&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Additional&lt;/h3&gt;
&lt;p&gt;(Some additional test data I leave here for future reference)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- data.frame(
  A_1 = c(2.3, 0.93, 0.62, 0.74, -0.23),
  A_2 = c(0.93, 1.40, 0.2, 0.56, 0.26),
  A_3 = c(0.62, 0.2, 1.80, 0.78, -0.27),
  A_4 = c(0.74, 0.56, 0.78, 3.4, -0.56),
  A_5 = c(-0.23, 0.26, -0.27, -0.56, 2.60),
  Security = c(1, 2, 3, 4, 5),
  R_i = c(15.1, 12.5, 14.7, 9.02, 17.68)
)

Sigma &amp;lt;- data[, 1:5]
w &amp;lt;- Variable(nrow(data))
mu &amp;lt;- data[, 7]
n_samples = 10
lambdas &amp;lt;- 10^seq(-2, 3, length.out = n_samples)

ret_data &amp;lt;- rep(0, n_samples)
risk_data &amp;lt;- rep(0, n_samples)
w_data &amp;lt;- matrix(0, nrow = n_samples, ncol = nrow(data))

for(i in seq_along(lambdas)) {
  lambda &amp;lt;- lambdas[i]
  problem &amp;lt;- Problem(
    Maximize(
      t(mu) %*% w - lambda*quad_form(w, Sigma)
    ),
    constraints = list(w &amp;gt;= 0, sum(w) == 1))
  solution &amp;lt;- solve(problem)
  w_data[i,] &amp;lt;- solution$getValue(w)
  risk_data[i] &amp;lt;- solution$getValue(sqrt(quad_form(w, Sigma)))
  ret_data[i] &amp;lt;- solution$getValue(t(mu) %*% w)
}

ggplot() +
  geom_line(mapping = aes(x = risk_data, y = ret_data), color = &amp;quot;blue&amp;quot;) +
  geom_point(mapping = aes(x = sqrt(diag(as.matrix(Sigma))), y = mu), color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/portfolio-optimisation-model/portfolio-optimisation-R_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>